{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcquZPJUhzhs"
      },
      "source": [
        "#Initiate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmBqE0aVhzht"
      },
      "source": [
        "##Requirements "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q77Dyigyhzht",
        "outputId": "49a08032-f4c0-4e2d-9428-ff466b9ae931"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting stable-baselines==2.10.2\n",
            "  Downloading stable_baselines-2.10.2-py3-none-any.whl (240 kB)\n",
            "\u001b[K     |████████████████████████████████| 240 kB 15.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from stable-baselines==2.10.2) (3.2.2)\n",
            "Requirement already satisfied: gym[atari,classic_control]>=0.11 in /usr/local/lib/python3.7/dist-packages (from stable-baselines==2.10.2) (0.17.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from stable-baselines==2.10.2) (1.3.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from stable-baselines==2.10.2) (1.1.0)\n",
            "Requirement already satisfied: cloudpickle>=0.5.5 in /usr/local/lib/python3.7/dist-packages (from stable-baselines==2.10.2) (1.3.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from stable-baselines==2.10.2) (4.1.2.30)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from stable-baselines==2.10.2) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stable-baselines==2.10.2) (1.21.6)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines==2.10.2) (1.5.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines==2.10.2) (7.1.2)\n",
            "Requirement already satisfied: atari-py~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines==2.10.2) (0.2.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from atari-py~=0.2.0->gym[atari,classic_control]>=0.11->stable-baselines==2.10.2) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[atari,classic_control]>=0.11->stable-baselines==2.10.2) (0.16.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines==2.10.2) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines==2.10.2) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines==2.10.2) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines==2.10.2) (1.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->stable-baselines==2.10.2) (4.2.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->stable-baselines==2.10.2) (2022.1)\n",
            "Installing collected packages: stable-baselines\n",
            "Successfully installed stable-baselines-2.10.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pymoo==0.4.2.2\n",
            "  Downloading pymoo-0.4.2.2.tar.gz (3.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7 MB 13.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from pymoo==0.4.2.2) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.7/dist-packages (from pymoo==0.4.2.2) (1.4.1)\n",
            "Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.7/dist-packages (from pymoo==0.4.2.2) (3.2.2)\n",
            "Requirement already satisfied: autograd>=1.3 in /usr/local/lib/python3.7/dist-packages (from pymoo==0.4.2.2) (1.4)\n",
            "Collecting cma==2.7\n",
            "  Downloading cma-2.7.0-py2.py3-none-any.whl (239 kB)\n",
            "\u001b[K     |████████████████████████████████| 239 kB 44.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.7/dist-packages (from autograd>=1.3->pymoo==0.4.2.2) (0.16.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3->pymoo==0.4.2.2) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3->pymoo==0.4.2.2) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3->pymoo==0.4.2.2) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3->pymoo==0.4.2.2) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=3->pymoo==0.4.2.2) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=3->pymoo==0.4.2.2) (1.15.0)\n",
            "Building wheels for collected packages: pymoo\n",
            "  Building wheel for pymoo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pymoo: filename=pymoo-0.4.2.2-cp37-cp37m-linux_x86_64.whl size=4939988 sha256=befdfdcf8d4b3caf9e7343bbbe9aba48e7515c5067dc6af88d3eb186b75de710\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/8c/89/c450ad360fc24cb70fec0388e8d95b51021eae5dab248ab76e\n",
            "Successfully built pymoo\n",
            "Installing collected packages: cma, pymoo\n",
            "Successfully installed cma-2.7.0 pymoo-0.4.2.2\n",
            "TensorFlow 1.x selected.\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install stable-baselines==2.10.2\n",
        "!pip install pymoo==0.4.2.2\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "\n",
        "import gym\n",
        "import numpy as np\n",
        "from stable_baselines import DQN\n",
        "from copy import deepcopy\n",
        "import math\n",
        "from gym.spaces import Discrete, Dict, Box\n",
        "from gym import spaces\n",
        "from random import seed\n",
        "import random \n",
        "from gym import Env\n",
        "from datetime import datetime\n",
        "import sys\n",
        "import time\n",
        "import pickle\n",
        "import stable_baselines\n",
        "import sklearn\n",
        "import numpy\n",
        "from sklearn import tree , svm \n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB , CategoricalNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "from itertools import product\n",
        "from sklearn.utils import resample\n",
        "from sklearn.model_selection import KFold , RepeatedKFold\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn import impute\n",
        "import statistics\n",
        "from scipy import stats\n",
        "from copy import deepcopy\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from math import ceil\n",
        "import copy\n",
        "import sys\n",
        "from sklearn.metrics import jaccard_score\n",
        "import time\n",
        "import multiprocessing\n",
        "from pymoo.algorithms.nsga2 import calc_crowding_distance\n",
        "sys.path.append('lib/')\n",
        "import subprocess\n",
        "import logging\n",
        "from sklearn.utils import shuffle\n",
        "import csv\n",
        "from csv import reader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLM7WPi_hzht",
        "outputId": "caf0e38c-8db1-44b4-baa7-298f92171476"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ipython-autotime\n",
            "  Downloading ipython_autotime-0.3.1-py2.py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from ipython-autotime) (5.5.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (5.1.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (2.6.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (1.0.18)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (57.4.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->ipython-autotime) (0.7.0)\n",
            "Installing collected packages: ipython-autotime\n",
            "Successfully installed ipython-autotime-0.3.1\n",
            "time: 191 µs (started: 2022-05-30 21:19:32 +00:00)\n"
          ]
        }
      ],
      "source": [
        "!pip install ipython-autotime\n",
        "\n",
        "%load_ext autotime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0m0tVtNwhzhu"
      },
      "source": [
        "##RL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jt-OWqbYhzhu",
        "outputId": "c57675b0-704b-435e-cfaa-5ee10affa1ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 1.2 s (started: 2022-05-30 21:19:32 +00:00)\n"
          ]
        }
      ],
      "source": [
        "class StoreWrapper(gym.Wrapper):\n",
        "  ''''\n",
        "  :param env: (gym.Env) Gym environment that will be wrapped\n",
        "  :param max_steps: (int) Max number of steps per episode\n",
        "  '''\n",
        "  def __init__(self, env):\n",
        "    # Call the parent constructor, so we can access self.env later\n",
        "    super(StoreWrapper, self).__init__(env)\n",
        "    self.max_steps = 200\n",
        "    # Counter of steps per episode\n",
        "    self.current_step = 0\n",
        "    self.mem = []\n",
        "    self.TotalReward = 0.0 \n",
        "    self.env = env\n",
        "    self.first_state = 0\n",
        "    self.first_obs = 0\n",
        "    self.prev_obs = 0 \n",
        "    self.states_list = []\n",
        "  \n",
        "  def reset(self):\n",
        "    \"\"\"\n",
        "    Reset the environment \n",
        "    \"\"\"\n",
        "    # Reset the counter\n",
        "    self.current_step = 0\n",
        "    obs =self.env.reset()\n",
        "    self.TotalReward = 0.0\n",
        "    self.first_obs = obs\n",
        "    return obs\n",
        "\n",
        "  def step(self, action):\n",
        "    \"\"\"\n",
        "    In this function we store the initial state as well as the memory of the agent\n",
        "    :param action: ([float] or int) Action taken by the agent\n",
        "    :return: (np.ndarray, float, bool, dict) observation, reward, is the episode over?, additional informations\n",
        "    \"\"\"\n",
        "    if self.current_step == 0: #store initial state\n",
        "      self.prev_obs = self.first_obs\n",
        "      self.first_state = deepcopy(self.env)\n",
        "      self.states_list.append(self.first_state)\n",
        "    self.current_step += 1\n",
        "    obs, reward, done, info = self.env.step(action)\n",
        "    self.TotalReward += reward\n",
        "    self.mem.append(tuple((self.prev_obs,action)))\n",
        "    self.prev_obs = obs\n",
        "    if self.current_step >= self.max_steps:\n",
        "      done = True\n",
        "      # Update the info dict to signal that the limit was exceeded\n",
        "    if done:\n",
        "      self.mem.append(tuple(('done',self.TotalReward)))\n",
        "    info['mem'] = self.mem\n",
        "    info['state'] = self.states_list\n",
        "    # self.mem.append(tuple(obs,action))\n",
        "    return obs, reward, done, info\n",
        "\n",
        "  def set_state(self, state):\n",
        "    \"\"\"\n",
        "    :param state: initial state of the episode\n",
        "    :return: environment is updated and observations is returned\n",
        "    \"\"\"\n",
        "    self.env = deepcopy(state)\n",
        "    obs = np.array(list(self.env.unwrapped.state))\n",
        "    self.current_step = 0\n",
        "    self.TotalReward = 0.0\n",
        "    self.first_obs = obs\n",
        "    return obs\n",
        "\n",
        "def proportional_sampling_whitout_replacement(index , size):\n",
        "  s=0\n",
        "  s = sum(np.array(index))\n",
        "  p = [ind/s for ind in index]\n",
        "  samples = np.random.choice(index,size=size,replace=False,p=p)\n",
        "  return samples\n",
        "\n",
        "def population_sample(episodes , ind,  pop_size , random_test_size, threshold, functional_fault_size, reward_fault_size):\n",
        "  \"\"\"\n",
        "  This function is meant to sample episodes from training after that you need to add test episodes using random_test \n",
        "  Set the parameters as you want but be careful the input episodes for this function is the memory of the agent and each step has seperate index \n",
        "  this function returs the final steps of the selected function then you need to extract that episodes from the input memore that is called 'episodes'\n",
        "  use the episodes extract function ... \n",
        "\n",
        "  samples n episodes from training n1 functinal faults and n2 reward faults \n",
        "  reward faults are episodes with reward bellow the thresthreshold \n",
        "  from random test samples M episodes m1 random episode and\n",
        "  m2 episodes with sudden reward change we dont have a sudden reward change in this example  \n",
        "  \"\"\"\n",
        "  epsilon = 0.05\n",
        "  index = []\n",
        "  functional_fault = []\n",
        "  reward_fault = []\n",
        "  start_states =[]\n",
        "  ind  = np.where(np.array(episodes)==('done',))\n",
        "  index= ind[0]\n",
        "  print(len(ind[0]),'episodes from training')\n",
        "  population=[]\n",
        "  for i in index:\n",
        "    _,r = episodes[i]\n",
        "    if abs(episodes[i-1][0][0])>(2.4-epsilon):\n",
        "      functional_fault.append(i)\n",
        "      print('function fault') \n",
        "    if r<threshold:\n",
        "      reward_fault.append(i)\n",
        "      print('reward fault')\n",
        "  if len(functional_fault)<functional_fault_size:\n",
        "    print('functional faults size is' ,len(functional_fault),' and its less than desired number' )\n",
        "    population += functional_fault\n",
        "    print('sampling more random episodes instead ...!')\n",
        "  if len(functional_fault)==functional_fault_size:\n",
        "    population += functional_fault\n",
        "  if len(functional_fault)>functional_fault_size:\n",
        "    # proportianl_sample_whitout_replacement()\n",
        "    sam1=proportional_sampling_whitout_replacement(functional_fault,functional_fault_size)\n",
        "    population += sam1\n",
        "  if len(reward_fault)<reward_fault_size:\n",
        "    print('reward faults size is' ,len(reward_fault),' and its less than desired number' )\n",
        "    population += reward_fault\n",
        "    print('sampling more random episodes instead ...!')\n",
        "  if len(reward_fault)==reward_fault_size:\n",
        "    population += reward_fault\n",
        "  if len(reward_fault)>reward_fault_size:\n",
        "    #proportional sampling\n",
        "    sam2 = proportional_sampling_whitout_replacement(reward_fault,reward_fault_size)\n",
        "    population += list(sam2)\n",
        "  r_size= pop_size-len(population)\n",
        "  # random_test(model,env,r_size)\n",
        "  print(len(reward_fault))\n",
        "  # population += reward_fault\n",
        "  return population , r_size\n",
        "\n",
        "\n",
        "def episode_extract(sampled_index, episodes):\n",
        "  epis = []\n",
        "  for i in sampled_index:\n",
        "    l=int(episodes[i][1])\n",
        "    slice1 = episodes[(i-l):(i+1)]\n",
        "    epis+=slice1\n",
        "  return epis\n",
        "\n",
        "\n",
        "def fitness_reward(episode):\n",
        "  \"\"\"\n",
        "  here the reward could be calculated as the lengh of the episode; Since the\n",
        "  reward of the cartpole is defined based on the number of steps without falling\n",
        "  last part of the episode contains the signal of ('done',reward)\n",
        "  \"\"\"\n",
        "  return len(episode)-1\n",
        "\n",
        "def fitness_confidence(episode, model, mode):\n",
        "  \"\"\"\n",
        "  confidence level is define as differences between the highest and\n",
        "  second highest action probabilities of selecting actions OR\n",
        "  the ratio between the highest and lowest/second highest action probability\n",
        "  :param `mode`: r for ration and m for differences \n",
        "  :param `model`: is the RL agent \n",
        "  :param `episode`: is the episode values or sequence from the rl \n",
        "  \"\"\"\n",
        "  cl = 0.0\n",
        "  for i in range(len(episode)):\n",
        "    if i==(len(episode)-1):\n",
        "        if episode[i][0]=='done':\n",
        "            return (cl/episode[i][1])\n",
        "        else:\n",
        "            assert False, \"last state is not done , reward\"\n",
        "    else:\n",
        "      prob=model.action_probability(episode[i][0])\n",
        "      high1=prob.argmax()\n",
        "      first = prob[high1]\n",
        "      temp = prob\n",
        "      temp[high1] = 0.0\n",
        "      high2= temp.argmax()\n",
        "      second = prob[high2]\n",
        "      if mode == 'r':\n",
        "        cl +=  (first/second)\n",
        "        #In the next version this will be updated to a normalized ratio to avoid having large values \n",
        "      if mode == 'm':\n",
        "        cl += (first - second) #To_Do: first - second / first +second this one is better \n",
        "  print(\"WARNING nothing returned\", episode )\n",
        "\n",
        "\n",
        "def fitness_reward_probability(ml, binary_episode):\n",
        "  \"\"\"\n",
        "  This function returns the third fitness funciton that is ment to guide the search toward\n",
        "  the episodes with a higher probability of a reward fault and as we have a minimizing \n",
        "  optimization funciton in MOSA we neeed to change this functionwe can either go with the\n",
        "  negation of the probability of the reward fault = 1-probability of the reward fault\n",
        "  that is equal to the probability of the bein a non-faulty episode\n",
        "  :param `ml`: RF_FF_1rep for functional fault\n",
        "  :param `binary episode`: episodes decodeed as having abstract states\n",
        "  \"\"\"\n",
        "  # return -(ml.predict_proba(episode)[0][1])\n",
        "  return ml.predict_proba(binary_episode)[0][0]\n",
        "\n",
        "def fitness_functional_probability(ml, binary_episode):\n",
        "  return ml.predict_proba(binary_episode)[0][0]\n",
        "\n",
        "\n",
        "def state_abstraction(model,state1,state2,d):\n",
        "  \"\"\"\n",
        "  This function compares to state, if they were in the same abstract class\n",
        "  function returs 'True' otherwise 'False'\n",
        "  \"\"\"\n",
        "  q_value1 = model.step_model.step([state1])\n",
        "  q_value2 = model.step_model.step([state2])\n",
        "  for i in range(len(q_value1[1][0])):\n",
        "    print(q_value1[1][0][i])\n",
        "    print(q_value2[1][0][i])\n",
        "    if ceil(q_value1[1][0][i]/d) == ceil(q_value2[1][0][i]/d):\n",
        "     continue\n",
        "    else:\n",
        "      return False\n",
        "  return True\n",
        "\n",
        "\n",
        "def abstract_state(model,state1,d):\n",
        "  if type(state1) == str:\n",
        "    if state1 == 'done':\n",
        "      return 'end'\n",
        "  q_value1 = model.step_model.step([state1])\n",
        "  return( ceil(q_value1[1][0][0]/d), ceil(q_value1[1][0][1]/d))\n",
        "\n",
        "\n",
        "#report function to check the performance metrics of the model\n",
        "def report(model2,x_train, y_train,x_test, y_test):\n",
        "  print(\"********************** reporting the result of the model **************************\")\n",
        "  print('The score for train data is {0}'.format(model2.score(x_train,y_train)))\n",
        "  print('The score for test data is {0}'.format(model2.score(x_test,y_test)))\n",
        "\n",
        "\n",
        "  predictions_train = model2.predict(x_train)\n",
        "  predictions_test = model2.predict(x_test)\n",
        "\n",
        "  print(\"\\n\\n--------------------------------------recall---------------------------------\")\n",
        "\n",
        "  print('the test recall for the class yes is {0}'.format(metrics.recall_score(y_test,predictions_test, pos_label=1)))\n",
        "  print('the test recall for the class no is {0}'.format(metrics.recall_score(y_test,predictions_test, pos_label=0)))\n",
        "\n",
        "  print('the training recall for the class yes is {0}'.format(metrics.recall_score(y_train,predictions_train, pos_label=1)))\n",
        "  print('the training recall for the class no is {0}'.format(metrics.recall_score(y_train,predictions_train, pos_label=0)))\n",
        "\n",
        "\n",
        "  print(\"\\n\\n--------------------------------------precision------------------------------\")\n",
        "\n",
        "\n",
        "  print('the test precision for the class yes is {0}'.format(metrics.precision_score(y_test,predictions_test, pos_label=1)))\n",
        "  print('the test precision for the class no is {0}'.format(metrics.precision_score(y_test,predictions_test, pos_label=0)))\n",
        "\n",
        "  print('the training precision for the class yes is {0}'.format(metrics.precision_score(y_train,predictions_train, pos_label=1)))\n",
        "  print('the training precision for the class no is {0}'.format(metrics.precision_score(y_train,predictions_train, pos_label=0)))\n",
        "\n",
        "  print(\"\\n\\n\")\n",
        "  print(classification_report(y_test, predictions_test, target_names=['NO ','yes']))\n",
        "\n",
        "  tn, fp, fn, tp = confusion_matrix(y_test, predictions_test).ravel()\n",
        "  specificity = tn / (tn+fp)\n",
        "  print(\"\\n\\nspecifity :\",specificity)\n",
        "  print(\"\\n\\n--------------------------------------confusion----------------------------\")\n",
        "  CM = metrics.confusion_matrix(y_test, predictions_test)\n",
        "  print(\"The confusion Matrix:\")\n",
        "  print(CM)\n",
        "  print('the accuracy score in {0}\\n\\n'.format(accuracy_score(y_test, predictions_test)))\n",
        "  print(\"********************** plotting the confusion matrix & ROC curve **************************\")\n",
        "  plot_confusion_matrix(model2, x_test, y_test)\n",
        "  metrics.plot_roc_curve(model2, x_test, y_test) \n",
        "  plt.show()\n",
        "\n",
        "#dump\n",
        "\n",
        "def dump_p(what, name):\n",
        "  with open(f'/content/drive/MyDrive/Data/{name}.pickle', 'wb') as file:\n",
        "      pickle.dump(what, file)\n",
        "\n",
        "\n",
        "# write function for load\n",
        "\n",
        "def load_p(to_what, name):\n",
        "  with open(f'/content/drive/MyDrive/Data/{name}.pickle', 'rb') as file2:\n",
        "    to_what = pickle.load(file2)\n",
        "\n",
        "\n",
        "def random_test_1(model, env, Num):\n",
        "  obs=env.reset()\n",
        "  counter = 1\n",
        "  episode_reward = 0.0\n",
        "  for i in range(Num):\n",
        "    action, _ = model.predict(obs, deterministic=True)\n",
        "    obs, reward, done, info = env.step(action)\n",
        "    # env.render()\n",
        "    episode_reward += reward\n",
        "    if done:\n",
        "      counter += 1\n",
        "      end = i\n",
        "      print(\"Reward:\", episode_reward, \"final state\", info['mem'][-2][0])\n",
        "      episode_reward = 0.0\n",
        "      obs = env.reset()\n",
        "  iter = deepcopy(counter)\n",
        "  u=1\n",
        "  while iter>1:\n",
        "    if info['mem'][-u][0]=='done':\n",
        "      lastpoint = -u\n",
        "      iter -= 1\n",
        "    u+=1\n",
        "  fin =Num - end\n",
        "  start = -Num -counter\n",
        "  randomtest = info['mem'][lastpoint:-fin]\n",
        "  ran_state = info['state'][(-counter+1):-1]\n",
        "  return randomtest , ran_state\n",
        "\n",
        "\n",
        "def fix_training(training_episodes,training_states):\n",
        "  buffer =[] \n",
        "  episodes_set = []\n",
        "  j=0\n",
        "  for i in range(len(training_episodes)):\n",
        "    if training_episodes[i][0] == 'done':\n",
        "      if i == 0:\n",
        "        continue\n",
        "      buffer.append(training_episodes[i])\n",
        "      episodes_set.append(buffer)\n",
        "      buffer=[]\n",
        "    else:\n",
        "      buffer.append(training_episodes[i])\n",
        "  if len(episodes_set)!=len(training_states):\n",
        "    del training_states[-1]\n",
        "  if len(episodes_set)!=len(training_states):\n",
        "    # assert False, 'problem in starting states'\n",
        "    print('problem in starting states')\n",
        "  return episodes_set , training_states\n",
        "\n",
        "def fix_testing(testing_episodes,testing_states,Env2):\n",
        "  buffer =[] \n",
        "  episodes_set = []\n",
        "  j=0\n",
        "  for i in range(len(testing_episodes)):\n",
        "    if testing_episodes[i][0] == 'done':\n",
        "      if i == 0:\n",
        "        continue\n",
        "      buffer.append(testing_episodes[i])\n",
        "      episodes_set.append(buffer)\n",
        "      buffer=[]\n",
        "    else:\n",
        "      buffer.append(testing_episodes[i])\n",
        "  if not (episodes_set[0][0][0]==Env2.set_state(testing_states[0])).all():\n",
        "    del testing_states[0]\n",
        "  if not (episodes_set[0][0][0]==Env2.set_state(testing_states[0])).all():\n",
        "    assert False, 'problem in starting states'\n",
        "  if len(episodes_set)!=len(testing_states):\n",
        "    del testing_states[-1]\n",
        "  if len(episodes_set)!=len(testing_states):\n",
        "    assert False, 'problem in data prepration'\n",
        "  return episodes_set , testing_states\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gF0qCyWjznN"
      },
      "source": [
        "##ML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPq2NIKLj3JT",
        "outputId": "66009b90-c0f3-4828-86fd-abf23b2d8aba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 38.4 ms (started: 2022-05-30 21:19:33 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def Abstract_classes(ep,abstraction_d,model):\n",
        "  d=abstraction_d\n",
        "  abs_states1=[]\n",
        "  for episode in ep:\n",
        "    for state,action in episode:\n",
        "      abs_st = abstract_state(model,state,d)\n",
        "      if abs_st == 'end':\n",
        "        continue\n",
        "      abs_states1.append(abs_st)\n",
        "  unique1=list(set(abs_states1))\n",
        "  uni1 = np.array(unique1)\n",
        "  a=len(abs_states1)\n",
        "  b=len(set(abs_states1))\n",
        "  print(\"abstract states:\",b)\n",
        "  print(\"Concrete states\",a)\n",
        "  print(\"ratio\",b/a)\n",
        "  return unique1,uni1\n",
        "\n",
        "\n",
        "def ML_first_representation(Abs_d,epsilon_functional_fault_boarder,uni1,model,ep,unique1):\n",
        "  d = Abs_d\n",
        "  # epsilon = 0.05\n",
        "  epsilon = epsilon_functional_fault_boarder\n",
        "  data1_x_b=[]\n",
        "  data1_y_b= [] \n",
        "  data1_y_f_b = []\n",
        "  functional_fault = False\n",
        "  reward_fault_threshold = 70\n",
        "  for episode in ep:\n",
        "    record = np.zeros(len(uni1))\n",
        "    for state, action in episode:\n",
        "      ab = abstract_state(model,state,d)\n",
        "      if ab == 'end':\n",
        "        # print(action)\n",
        "        if functional_fault:\n",
        "          data1_y_f_b.append(1)\n",
        "        else:\n",
        "          data1_y_f_b.append(0)\n",
        "        if action >= reward_fault_threshold:\n",
        "          data1_y_b.append(0)\n",
        "        else:\n",
        "          data1_y_b.append(1)\n",
        "        functional_fault=False\n",
        "        continue\n",
        "      if abs(state[0]) >= (2.4-epsilon) :\n",
        "        functional_fault = True\n",
        "      ind = unique1.index(ab)\n",
        "      # if len(w[0])>1:\n",
        "        # print('error len is greater than 1')\n",
        "      record[ind] = 1\n",
        "      # if you want the frequency go with the next line \n",
        "      # record[ind] += 1\n",
        "    data1_x_b.append(record)\n",
        "\n",
        "  return data1_x_b, data1_y_b, data1_y_f_b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2Zbn-uNhzhv"
      },
      "source": [
        "##Genetic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CvmHY7shzhv",
        "outputId": "d4a3a2eb-c432-47a5-84bd-f3f62c47e72d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 985 ms (started: 2022-05-30 21:19:33 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def translator(episode,model, d, unique5):\n",
        "  \"\"\"\n",
        "  thid function takes the concrete episodes and returns the encoded episodes \n",
        "  based on the presence and absence of the individuals  \n",
        "  :param 'episode': input episode\n",
        "  :param 'model': RL model\n",
        "  :param 'd': abstraction level = 1\n",
        "  :param 'unique5': abstract classes \n",
        "  :return: encoded episodse based on the presence and absence\n",
        "\n",
        "  \"\"\"\n",
        "  d=d\n",
        "  record = np.zeros(len(unique5))\n",
        "  for state, action in episode:\n",
        "    ab = abstract_state(model,state,d)\n",
        "    if ab == 'end':\n",
        "      continue\n",
        "    if ab in unique5:\n",
        "      ind = unique5.index(ab)\n",
        "    record[ind] = 1\n",
        "  return [record]\n",
        "\n",
        "def transform(state):\n",
        "  position = state[0]\n",
        "  noise = np.random.uniform(low=0.95, high=1.05)\n",
        "  new_position= position * noise \n",
        "  new_state =deepcopy(state)\n",
        "  new_state[0] = new_position \n",
        "  #if new_position>2.4:\n",
        "  # newstate = 2.4\n",
        "  #if new_position<-2.4:\n",
        "  # newstate = -2.4\n",
        "  return new_state\n",
        "\n",
        "\n",
        "def mutation_improved(population,model,env,objective_uncovered):\n",
        "  \"\"\"\n",
        "  This is the final mutation function \n",
        "  It takes the population as input and returns the mutated individual\n",
        "  :param 'population': Population that we want to mutate \n",
        "  :param 'model': RL model\n",
        "  :param 'env': RL environment\n",
        "  :param 'objective_uncovered: uncovered ubjectives for tournament selection\n",
        "  :return: mutated candidate (we re-rexecute the episode from the mutation part)\n",
        "  To-do:\n",
        "  move deepcopy to the cadidate class methods .set info \n",
        "  \"\"\"\n",
        "  parent = tournament_selection(population, 10, objective_uncovered)  # tournament selection\n",
        "  parent1 = deepcopy(parent.get_candidate_values())\n",
        "  if len(parent1) < 3:\n",
        "     assert False , \"parent in mutation is shorter than 3\"\n",
        "  Mutpoint = random.randint(3,(len(parent1)-3))\n",
        "  new_state = transform(parent1[Mutpoint][0])\n",
        "  action = model.predict(new_state)\n",
        "  if action[0]!= int(parent1[Mutpoint][1]):\n",
        "    print('Mutation lured the agent ... ')\n",
        "  new_parent = parent1[:Mutpoint]\n",
        "  new_parent.append([new_state,'Mut'])\n",
        "  new_cand =Candidate(new_parent)\n",
        "  new_cand.set_start_state(parent.get_start_state())\n",
        "\n",
        "  re_executed_epis = re_execute(model,env,new_cand)\n",
        "  \n",
        "  re_executed_cand = Candidate(re_executed_epis)\n",
        "  re_executed_cand.set_start_state(new_cand.get_start_state())\n",
        "  re_executed_cand.set_info(deepcopy(parent.get_info()))\n",
        "  re_executed_cand.set_info([\"mutation is done! \", \"mutpoint was:\",Mutpoint])\n",
        "\n",
        "  \n",
        "  return re_executed_cand\n",
        "\n",
        "def mutation_improved_p(parent,model,env,m_rate):\n",
        "  \"\"\"\n",
        "  This is the final mutation function with input of a parent considering internal m_rate\n",
        "  Here we give the parent to themutation funcion based on the given mutation \n",
        "  rate of m_rate, we may mutate the episodes. \n",
        "  :param 'parent' : individual that we want to mutate\n",
        "  :param 'model': RL model\n",
        "  :param 'env': RL environment\n",
        "  :param 'm_rate': mutation : recommended value is 1/len(parent)\n",
        "  :return : mutated individual\n",
        "  To-do:\n",
        "  move deepcopy to the cadidate .set info \n",
        "  \"\"\"\n",
        "  # parent = tournament_selection(population, 10, objective_uncovered)  # tournament selection\n",
        "  global MUTATION_NUMBER\n",
        "  chance = random.uniform(0, 1)\n",
        "  if chance> m_rate:\n",
        "    return parent\n",
        "  else:\n",
        "    parent1 = deepcopy(parent.get_candidate_values())\n",
        "    if len(parent1) < 3:\n",
        "      assert False , \"parent in mutation is shorter than 3\"\n",
        "    Mutpoint = random.randint(3,(len(parent1)-3))\n",
        "    new_state = transform(parent1[Mutpoint][0])\n",
        "    action = model.predict(new_state)\n",
        "    if action[0]!= int(parent1[Mutpoint][1]):\n",
        "      print('Mutation lured the agent ... ')\n",
        "    new_parent = parent1[:Mutpoint]\n",
        "    new_parent.append([new_state,'Mut'])\n",
        "    new_cand =Candidate(new_parent)\n",
        "    new_cand.set_start_state(parent.get_start_state())\n",
        "    re_executed_epis = re_execute(model,env,new_cand)\n",
        "    re_executed_cand = Candidate(re_executed_epis)\n",
        "    re_executed_cand.set_start_state(new_cand.get_start_state())\n",
        "    re_executed_cand.set_info(deepcopy(parent.get_info()))\n",
        "    re_executed_cand.set_info([\"mutation is done! \", \"mutpoint was:\",Mutpoint])\n",
        "    MUTATION_NUMBER+=1\n",
        "    return re_executed_cand\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def Crossover_improved_v2(population,model,d,objective_uncovered):\n",
        "  \"\"\"\n",
        "  This is the crossover function that we are using \n",
        "  It takes the population as input and returns the mutated individual\n",
        "  :param 'population': Population. we select a parent based on the tournament\n",
        "   selection and then select the mutation point and then search for the matching point. \n",
        "  :param 'model': RL model\n",
        "  :param 'env': RL environment\n",
        "  :param 'objective_uncovered: uncovered ubjectives for tournament selection\n",
        "  :return: mutated candidate (we re-rexecute the episode from the mutation part)\n",
        "  To-do:\n",
        "  finding matching episode could be improved bu storing a mapping between concrete states and  \n",
        "  \"\"\"\n",
        "  found_match = False \n",
        "  while not (found_match):\n",
        "    parent = tournament_selection(population, 10, objective_uncovered)  # tournament selection\n",
        "    parent1 = deepcopy(parent.get_candidate_values())\n",
        "    parent1_start_point = deepcopy(parent.get_start_state())\n",
        "    if len(parent1)<4:\n",
        "      assert False, 'input of crossover is shorter than expected '\n",
        "    matches_list = []\n",
        "    crosspoint = random.randint(1,(len(parent1)-3))\n",
        "    abs_class = list(abstract_state(model,parent1[crosspoint][0],d))\n",
        "    for i in range(50):\n",
        "      indx = random.randint(0, len(population) - 1)\n",
        "      random_candidate = deepcopy(population[indx])\n",
        "      random_cand_data = random_candidate.get_candidate_values()\n",
        "      random_cand_start_point = random_candidate.get_start_state()\n",
        "      for st_index in range(1,len(random_cand_data)-3):\n",
        "        random_ab = list(abstract_state(model,random_cand_data[st_index][0],d))\n",
        "        if random_ab == abs_class:\n",
        "          matches_list.append(st_index)\n",
        "          found_match = True\n",
        "      if found_match:\n",
        "        break \n",
        "  # print('Crossover. attemp',i)\n",
        "  index_match_in_matchlist = random.randint(0, len(matches_list) - 1)\n",
        "  matchpoint = matches_list[index_match_in_matchlist]\n",
        "  match_candidate =  deepcopy(random_candidate)\n",
        "  match = deepcopy(random_cand_data)\n",
        "  match_start = deepcopy(random_cand_start_point)\n",
        "  offspring1 = deepcopy(parent1[:crosspoint])\n",
        "  offspring1 += deepcopy(match[matchpoint:])\n",
        "  offspring1[-1] = ['done',(len(offspring1)-1)]\n",
        "  candid1 = Candidate(offspring1)\n",
        "  candid1.set_start_state(parent1_start_point)\n",
        "  candid1.set_info(deepcopy(parent.get_info()))\n",
        "  candid1.set_info([\"crossover is Done!\", \"the crossover point is:\",crosspoint])\n",
        "  offspring2 = deepcopy(match[:matchpoint])\n",
        "  offspring2 += deepcopy(parent1[crosspoint:])\n",
        "  offspring2[-1] = ['done',(len(offspring2)-1)]\n",
        "  candid2 = Candidate(offspring2)\n",
        "  candid2.set_start_state(match_start)\n",
        "  candid2.set_info(deepcopy(match_candidate.get_info()))\n",
        "  candid2.set_info([\"crossover is Done!\", \"the crossover point is:\",matchpoint])\n",
        "\n",
        "  if len(offspring1)<4:\n",
        "    print(offspring1)\n",
        "    assert False, 'created offspring 1 in crossover is shorter than expected '\n",
        "\n",
        "  if len(offspring2)<4:\n",
        "    print(offspring2)\n",
        "    assert False, 'created offspring 2 in crossover is shorter than expected '\n",
        "\n",
        "  return candid1, candid2\n",
        "\n",
        "\n",
        "\n",
        "def Crossover_improved_v2_random(population,model,d,objective_uncovered):\n",
        "  found_match = False \n",
        "  while not found_match:\n",
        "    i = random.randint(0, len(population))\n",
        "    parent1 = deepcopy(population[i].get_candidate_values())\n",
        "    parent1_start_point = deepcopy(population[i].get_start_state())\n",
        "    matches_list = []\n",
        "    crosspoint = random.randint(1,(len(parent1)-3))\n",
        "    abs_class = list(abstract_state(model,parent1[crosspoint][0],d))\n",
        "    attemp = 0\n",
        "    for i in range(700):\n",
        "      attemp +=1\n",
        "      indx = random.randint(0, len(population) - 1)\n",
        "      random_candidate = deepcopy(population[indx])\n",
        "      random_cand_data = random_candidate.get_candidate_values()\n",
        "      random_cand_start_point = random_candidate.get_start_state()\n",
        "      for st_index in range(1,len(random_cand_data)-3):\n",
        "        random_ab = list(abstract_state(model,random_cand_data[st_index][0],d))\n",
        "        if random_ab == abs_class:\n",
        "          matches_list.append(st_index)\n",
        "          found_match = True\n",
        "      if found_match:\n",
        "        break \n",
        "  print(\"match found in --- attemps\",attemp)\n",
        "  index_match_in_matchlist = random.randint(0, len(matches_list) - 1)\n",
        "  matchpoint = matches_list[index_match_in_matchlist]\n",
        "  match_candidate = random_candidate\n",
        "  match = random_cand_data\n",
        "  match_start = deepcopy(random_cand_start_point)\n",
        "  offspring1 = deepcopy(parent1[:crosspoint])\n",
        "  offspring1 += deepcopy(match[matchpoint:])\n",
        "  offspring1[-1] = ['done',(len(offspring1)-1)]\n",
        "  candid1 = Candidate(offspring1)\n",
        "  candid1.set_start_state(parent1_start_point)\n",
        "\n",
        "  offspring2 = deepcopy(match[:matchpoint])\n",
        "  offspring2 += deepcopy(parent1[crosspoint:])\n",
        "  offspring2[-1] = ['done',(len(offspring2)-1)]\n",
        "  candid2 = Candidate(offspring2)\n",
        "  candid2.set_start_state(match_start)\n",
        "  return candid1, candid2\n",
        "\n",
        "\n",
        "def re_execute(model,env,candidate):\n",
        "  obs =env.reset()\n",
        "  obs =env.set_state(deepcopy(candidate.get_start_state()))\n",
        "  episode = candidate.get_candidate_values()\n",
        "  steps_to_mut_point = len(episode)\n",
        "  episode_reward = 0.0\n",
        "  done= False \n",
        "  for i in range(steps_to_mut_point):\n",
        "    action, _ = model.predict(obs, deterministic=True)\n",
        "    action_selected = episode[i][1]\n",
        "    if action_selected == 'Mut':\n",
        "      action_selected, _ = model.predict(episode[i][0], deterministic=True)\n",
        "      # break\n",
        "    obs, reward, done, info = env.step(int(action_selected)) # its very important to select the action here it means that we may \n",
        "    #follow the previous path until the mutation point or we follow the route that the trained agent wants to follow forcing vs following \n",
        "    # env.render()\n",
        "    episode_reward += reward\n",
        "    if done:\n",
        "      break \n",
        "  # for j in range(200 - steps_to_mut_point): ###changed \n",
        "  for j in range(400):\n",
        "    if done:\n",
        "      break\n",
        "    action, _ = model.predict(obs, deterministic=True)\n",
        "    obs, reward, done, info = env.step(action) \n",
        "    # env.render()\n",
        "    # env.reset = state1\n",
        "    episode_reward += reward\n",
        "    if reward >201:\n",
        "      assert False\n",
        "  assert done\n",
        "  if episode_reward>201:\n",
        "    assert False \n",
        "  return info['mem'][-(int(episode_reward)+1):]\n",
        "\n",
        "\n",
        "def re_execution_improved(model,env,candidate):\n",
        "  differences=[]\n",
        "  episode_limit = 200 \n",
        "  env.reset()\n",
        "  obs =env.set_state(candidate.get_start_state()) \n",
        "  episode = candidate.get_candidate_values()\n",
        "  # steps_to_mut_point = len(episode)\n",
        "  episode_reward = 0.0\n",
        "  for i in range(episode_limit):\n",
        "    action, _ = model.predict(obs, deterministic=True)\n",
        "    action_selected = episode[i][1]\n",
        "    if  episode[i][0]=='done':\n",
        "      continue\n",
        "    if i >=len(episode):\n",
        "      action, _ = model.predict(obs, deterministic=True)\n",
        "      obs, reward, done, info = env.step(int(action)) \n",
        "      continue\n",
        "    if action != int(action_selected):\n",
        "      prob=model.action_probability(episode[i][0])\n",
        "      differences.append([i , prob])\n",
        "    obs, reward, done, info = env.step(int(action_selected))\n",
        "    # env.render()\n",
        "    # env.reset = state1\n",
        "    episode_reward += reward\n",
        "    if done:\n",
        "      # assert not done\n",
        "      break \n",
        "  assert done , \"not finished in 2oo steps \"\n",
        "  return differences\n",
        "\n",
        "\n",
        "def re_execution_improved_v2(model,env,candidate):\n",
        "  differences=[]\n",
        "  episode_limit = 200 \n",
        "  env.reset()\n",
        "  obs =env.set_state(candidate.get_start_state()) \n",
        "  episode = candidate.get_candidate_values()\n",
        "  episode_reward = 0.0\n",
        "  for i in range(episode_limit):\n",
        "    if i >=(len(episode)-1):\n",
        "      action, _ = model.predict(obs, deterministic=True)\n",
        "      obs, reward, done, info = env.step(int(action)) \n",
        "      if done:\n",
        "      # assert not done\n",
        "        print(\"Reward:\", episode_reward)\n",
        "        # break\n",
        "        return differences \n",
        "      continue\n",
        "    action, _ = model.predict(obs, deterministic=True)\n",
        "    if  episode[i][0]=='done':\n",
        "      print(\"first scenario, episode finished correctly\")\n",
        "      # continue\n",
        "    print(len(episode),i)\n",
        "    action_selected = episode[i][1]\n",
        "    if action != int(action_selected):\n",
        "      prob=model.action_probability(episode[i][0])\n",
        "      differences.append([i , prob])\n",
        "    obs, reward, done, info = env.step(int(action_selected)) \n",
        "    # env.render()\n",
        "    # env.reset = state1\n",
        "    episode_reward += reward\n",
        "    if done:\n",
        "      # assert not done\n",
        "      break \n",
        "  assert done , \"not finished in 2oo steps \"\n",
        "  return differences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okfUHBX8hzhw",
        "outputId": "c204bda8-f2bb-4c38-c178-de0e2359bb3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 50.8 ms (started: 2022-05-30 21:19:34 +00:00)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "class Candidate:\n",
        "    def __init__(self, candidates_vals):\n",
        "        if isinstance(candidates_vals, (np.ndarray, np.generic)):\n",
        "            self.candidate_values = candidates_vals.tolist()\n",
        "        else:\n",
        "            self.candidate_values = candidates_vals\n",
        "        self.objective_values = []\n",
        "        self.objectives_covered = []\n",
        "        self.crowding_distance = 0\n",
        "        self.uncertainity = []\n",
        "        self.start_state = 0\n",
        "        self.information = []\n",
        "        self.mutation = False\n",
        "\n",
        "    def get_candidate_values(self):\n",
        "        return self.candidate_values\n",
        "\n",
        "    def get_uncertainity_value(self, indx):\n",
        "        return self.uncertainity[indx]\n",
        "    def get_uncertainity_values(self):\n",
        "        return self.uncertainity\n",
        "    def set_uncertainity_values(self,uncertain):\n",
        "        self.uncertainity = uncertain\n",
        "    def set_candidate_values(self, cand):\n",
        "        self.candidate_values = cand\n",
        "    def set_candidate_values_at_index(self, indx,val):\n",
        "        self.candidate_values[indx] = val\n",
        "\n",
        "    def get_objective_values(self):\n",
        "        return self.objective_values\n",
        "\n",
        "    def get_objective_value(self, indx):\n",
        "        return self.objective_values[indx]\n",
        "\n",
        "    def set_objective_values(self, obj_vals):\n",
        "        self.objective_values = obj_vals\n",
        "\n",
        "    def add_objectives_covered(self, obj_covered):\n",
        "        if obj_covered not in self.objectives_covered:\n",
        "            self.objectives_covered.append(obj_covered)\n",
        "\n",
        "    def get_covered_objectives(self):\n",
        "        return self.objectives_covered\n",
        "\n",
        "    def set_crowding_distance(self, cd):\n",
        "        self.crowding_distance = cd\n",
        "\n",
        "    def get_crowding_distance(self):\n",
        "        return self.crowding_distance\n",
        "\n",
        "    def exists_in_satisfied(self, indx):\n",
        "        for ind in self.objectives_covered:\n",
        "            if ind == indx:\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def is_objective_covered(self, obj_to_check):\n",
        "        for obj in self.objectives_covered:\n",
        "            if obj == obj_to_check:\n",
        "                return True\n",
        "        return False\n",
        "    def set_start_state(self,start_point):\n",
        "      self.start_state = deepcopy(start_point)\n",
        "\n",
        "    def get_start_state(self):\n",
        "      return self.start_state\n",
        "\n",
        "    def set_info(self, new_information):\n",
        "      self.information.append(new_information)\n",
        "      \n",
        "    def get_info(self):\n",
        "      return self.information\n",
        "\n",
        "    def mutated(self):\n",
        "      self.mutation = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAfz-sEuTXmG",
        "outputId": "948f450a-c18e-4551-a43b-91d354b18f08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 10.2 ms (started: 2022-05-30 21:19:34 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def mutation_number_update(file_address,Mut_Num_to_add,iteration):\n",
        "  if iteration == 0:\n",
        "    with open(file_address, 'wb') as file:\n",
        "      pickle.dump(Mut_Num_to_add, file)\n",
        "    return\n",
        "  with open(file_address, 'rb') as file2:\n",
        "    Mut_num = pickle.load(file2)\n",
        "  print(Mut_num)\n",
        "  if type(Mut_num) == list:\n",
        "    print('list')\n",
        "    buffer = Mut_num\n",
        "    buffer.append(Mut_Num_to_add)\n",
        "    print(buffer)\n",
        "  else:\n",
        "    print('int')\n",
        "    buffer =[] \n",
        "    buffer.append(Mut_num)\n",
        "    buffer.append(Mut_Num_to_add)\n",
        "    print(buffer)\n",
        "  with open(file_address, 'wb') as file:\n",
        "    pickle.dump(buffer, file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnyQxUHUhzhw"
      },
      "source": [
        "##MOSA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7j3rzFayhzhw",
        "outputId": "a95e81ce-1225-48e4-f621-3e7238c52be6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 473 ms (started: 2022-05-30 21:19:34 +00:00)\n"
          ]
        }
      ],
      "source": [
        "scaler = preprocessing.StandardScaler()\n",
        "\n",
        "\n",
        "\n",
        "# domination relation method, same as MOSA \n",
        "def dominates(value_from_pop, value_from_archive, objective_uncovered):\n",
        "    dominates_f1 = False\n",
        "    dominates_f2 = False\n",
        "    for each_objective in objective_uncovered:\n",
        "        f1 = value_from_pop[each_objective]\n",
        "        f2 = value_from_archive[each_objective]\n",
        "        if f1 < f2:\n",
        "            dominates_f1 = True\n",
        "        if f2 < f1:\n",
        "            dominates_f2 = True\n",
        "        if dominates_f1 and dominates_f2:\n",
        "            break\n",
        "    if dominates_f1 == dominates_f2:\n",
        "        return False\n",
        "    elif dominates_f1:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# calculating the fitness value function\n",
        "\n",
        "def evaulate_population(func, pop , parameters):\n",
        "    for candidate in pop:\n",
        "      if isinstance(candidate, Candidate):\n",
        "        result = func(candidate.get_candidate_values())\n",
        "        candidate.set_objective_values(result)\n",
        "        print(candidate.get_objective_values())\n",
        "\n",
        "def evaulate_population_with_archive(func, pop, already_executed):\n",
        "    to_ret = []\n",
        "    for candidate in pop:\n",
        "        if isinstance(candidate, Candidate):\n",
        "            if candidate.get_candidate_values() in already_executed:\n",
        "                continue\n",
        "\n",
        "            result = func(candidate.get_candidate_values())\n",
        "            candidate.set_objective_values(result)\n",
        "            already_executed.append(candidate.get_candidate_values())\n",
        "            to_ret.append(candidate)\n",
        "    return to_ret\n",
        "\n",
        "def exists_in_archive(archive, index):\n",
        "    for candidate in archive:\n",
        "        if candidate.exists_in_satisfied(index):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "\n",
        "# searching archive\n",
        "def get_from_archive(obj_index, archive):\n",
        "    for candIndx in range(len(archive)):\n",
        "        candidate = archive[candIndx]\n",
        "        if candidate.exists_in_satisfied(obj_index):\n",
        "            return candidate, candIndx\n",
        "    return None\n",
        "\n",
        "\n",
        "# updating archive with adding the number of objective it satisfies, Same as Mosa paper\n",
        "def update_archive(pop, objective_uncovered, archive, no_of_Objectives, threshold_criteria):\n",
        "    for objective_index in range(no_of_Objectives):\n",
        "        for pop_index in range(len(pop)):\n",
        "            objective_values = pop[pop_index].get_objective_values()\n",
        "            # if not objective_values[objective_index] or not threshold_criteria[objective_index]:\n",
        "            if objective_values[objective_index] <= threshold_criteria[objective_index]:\n",
        "                if exists_in_archive(archive, objective_index):\n",
        "                    archive_value, cand_indx = get_from_archive(objective_index, archive)\n",
        "                    obj_archive_values = archive_value.get_objective_values()\n",
        "                    if obj_archive_values[objective_index] > objective_values[objective_index]:\n",
        "                        value_to_add = pop[pop_index]\n",
        "                        value_to_add.add_objectives_covered(objective_index)\n",
        "                        # archive.append(value_to_add)\n",
        "                        archive[cand_indx] = value_to_add\n",
        "                        if objective_index in objective_uncovered:\n",
        "                            objective_uncovered.remove(objective_index)\n",
        "                        # archive.remove(archive_value)\n",
        "                else:\n",
        "                    value_to_add = pop[pop_index]\n",
        "                    value_to_add.add_objectives_covered(objective_index)\n",
        "                    archive.append(value_to_add)\n",
        "                    if objective_index in objective_uncovered:\n",
        "                        objective_uncovered.remove(objective_index)\n",
        "\n",
        "\n",
        "# method to get the most dominating one\n",
        "def select_best(tournament_candidates, objective_uncovered):\n",
        "    best = tournament_candidates[0]  # in case none is dominating other\n",
        "    for i in range(len(tournament_candidates)):\n",
        "        candidate1 = tournament_candidates[i]\n",
        "        for j in range(len(tournament_candidates)):\n",
        "            candidate2 = tournament_candidates[j]\n",
        "            if (dominates(candidate1.get_objective_values(), candidate2.get_objective_values(), objective_uncovered)):\n",
        "                best = candidate1\n",
        "    return best\n",
        "\n",
        "\n",
        "def tournament_selection_improved(pop, size, objective_uncovered):\n",
        "    tournament_candidates = []\n",
        "    for i in range(size):\n",
        "        indx = random.randint(0, len(pop) - 1)\n",
        "        random_candidate = pop[indx]\n",
        "        tournament_candidates.append(random_candidate)\n",
        "\n",
        "    best = select_best(tournament_candidates, objective_uncovered)\n",
        "    return best;\n",
        "\n",
        "\n",
        "def tournament_selection(pop, size, objective_uncovered):\n",
        "    tournament_candidates = []\n",
        "    for i in range(size):\n",
        "        indx = random.randint(0, len(pop) - 1)\n",
        "        random_candidate = pop[indx]\n",
        "        tournament_candidates.append(random_candidate)\n",
        "\n",
        "    best = select_best(tournament_candidates, objective_uncovered)\n",
        "    return best;\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def generate_offspring_improved(population,model,env,d,objective_uncovered):\n",
        "    population_to_return = []\n",
        "    probability_C = 0.75\n",
        "    probability_M = 0.3\n",
        "    size = len(population)\n",
        "    while (len(population_to_return) < size):\n",
        "      probability_crossover = random.uniform(0, 1)\n",
        "      if probability_crossover <= probability_C:  # 75% probability\n",
        "        off1, off2 = Crossover_improved_v2(population,model,1,objective_uncovered)\n",
        "        population_to_return.append(off1)\n",
        "        population_to_return.append(off2)\n",
        "      probability_mutation = random.uniform(0, 1)\n",
        "      if probability_mutation <= probability_M:  # 30% probability this in for test purposes \n",
        "        off3 = mutation_improved(population, model,env,objective_uncovered)\n",
        "        population_to_return.append(off3)\n",
        "    return population_to_return\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def generate_offspring_improved_v2(population,model,env,d,objective_uncovered):\n",
        "    \n",
        "    population_to_return = []\n",
        "    probability_C = 0.75\n",
        "    probability_M = 0.01\n",
        "    size = len(population)\n",
        "    while (len(population_to_return) < size):\n",
        "      probability_crossover = random.uniform(0, 1)\n",
        "      if probability_crossover <= probability_C:  # 75% probability\n",
        "        parent1, parent2 = Crossover_improved_v2(population,model,d,objective_uncovered)\n",
        "        parent1 = mutation_improved_p(parent1, model,env, (1 / len(parent1.get_candidate_values())))\n",
        "        parent2 = mutation_improved_p(parent2, model,env, (1 / len(parent1.get_candidate_values())))\n",
        "        population_to_return.append(parent1)\n",
        "        population_to_return.append(parent2)\n",
        "\n",
        "      if probability_crossover > probability_C:\n",
        "        parent = tournament_selection(population, 10, objective_uncovered)\n",
        "        population_to_return.append(mutation_improved_p(parent, model,env,probability_M))\n",
        "      \n",
        "\n",
        "    return population_to_return\n",
        "\n",
        "\n",
        "\n",
        "def save_all_data(pop,no_of_Objectives,threshold_criteria, stored_data):\n",
        "  '''\n",
        "  This function will save all individulas with objective lower than treshhold \n",
        "\n",
        "  '''\n",
        "  threshold_criteria_to_add_to_archive = [70, 0.06, 0.05, 0.05] \n",
        "  # be careful here ypu can set the satisfiing objectives that based on them you want to store the data  \n",
        "  for individual in pop:\n",
        "    individual_objective = individual.get_objective_values()\n",
        "    for i in range(no_of_Objectives):\n",
        "      if individual_objective[i]<threshold_criteria_to_add_to_archive[i]:\n",
        "        # if individual not in stored_data:\n",
        "        #   ind_ = deepcopy(individual)\n",
        "        #   stored_data.append(ind_)\n",
        "        # individual_objective_values = individual.get_objective_values()\n",
        "        found = False\n",
        "        for j in range(len(stored_data)):\n",
        "          if individual_objective == stored_data[j].get_objective_values():\n",
        "            found = True\n",
        "            break\n",
        "        if not found:\n",
        "          ind_ = deepcopy(individual)\n",
        "          stored_data.append(ind_)\n",
        "  # return stored_data\n",
        "\n",
        "def save_all_data2(pop, stored_data):\n",
        "  '''\n",
        "  This function will save all individulas in generations \n",
        "  you need to remove redundant data (based on fitness and ...)\n",
        "\n",
        "  '''\n",
        "  stored_data.append(list(pop))\n",
        "\n",
        "def Build_Archive(pop,no_of_Objectives,threshold_criteria, stored_data, initial_population):\n",
        "  '''\n",
        "  If you are using the Archive of all generated episodes, this function\n",
        "  removes the duplicated results and builds the Archive.\n",
        "  :param 'pop': current generation\n",
        "  :param 'no_of_Objectives': number of objectives\n",
        "  :param 'threshold_criteria': threshold criteria (we are intrested in episodes that have fitness below these threshold values)\n",
        "  :param 'stored_data': Archive of final episodes (return)\n",
        "  :param 'initial_population': initial population. we are not considering these episodes in our archive for the second senario you need to add the number of faults, (implementation in RQ3)\n",
        "  '''\n",
        "  threshold_criteria_to_add_to_archive = threshold_criteria\n",
        "# be careful as we can have different values for criterias here to add episodes to archive and for GA stopping criteria \n",
        "  for individual in pop:\n",
        "    individual_objective = individual.get_objective_values()\n",
        "    for i in range(no_of_Objectives):\n",
        "      if individual_objective[i]<threshold_criteria_to_add_to_archive[i]:\n",
        "        found = False\n",
        "        for j in range(len(stored_data)):\n",
        "          if individual_objective == stored_data[j].get_objective_values():\n",
        "            found = True\n",
        "            break\n",
        "        for k in range(len(initial_population)):\n",
        "          if individual_objective == initial_population[k].get_objective_values():\n",
        "            found = True\n",
        "            break\n",
        "        if not found:\n",
        "          ind_ = deepcopy(individual)\n",
        "          stored_data.append(ind_)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQoVgLVmhzhx"
      },
      "source": [
        "###Sorting and RUN search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcMGMG-ohzhx",
        "outputId": "38ee1d21-d495-443c-b7bf-84f8f931f20a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 332 ms (started: 2022-05-30 21:19:35 +00:00)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# finding best candidates and assigning to each front\n",
        "def fast_dominating_sort(R_T, objective_uncovered):\n",
        "    to_return = []\n",
        "    front = []\n",
        "    count = 0\n",
        "    while len(R_T) > 1:\n",
        "        count = 0\n",
        "        for outer_loop in range(len(R_T)):\n",
        "            best = R_T[outer_loop]\n",
        "            add = True\n",
        "            for inner_loop in range(len(R_T)):\n",
        "                against = R_T[inner_loop]\n",
        "                if best == against:\n",
        "                    continue\n",
        "                if (dominates(best.get_objective_values(), against.get_objective_values(), objective_uncovered)):\n",
        "                    continue\n",
        "                else:\n",
        "                    add = False\n",
        "                    break\n",
        "\n",
        "            if add == True:\n",
        "                if best not in front:\n",
        "                    front.append(best)\n",
        "\n",
        "                count = count + 1\n",
        "\n",
        "        if len(front) > 0:\n",
        "            to_return.append(front)\n",
        "            for i in range(len(front)):\n",
        "                R_T.remove(front[i])\n",
        "                front = []\n",
        "\n",
        "        if (len(to_return) == 0) or (count == 0):  # to check if no one dominates no one\n",
        "            to_return.append(R_T)\n",
        "            break\n",
        "\n",
        "    return to_return\n",
        "\n",
        "\n",
        "# sorting based on crowding distance\n",
        "def sort_based_on_crowding_distance(e):\n",
        "    values = e.get_crowding_distance()\n",
        "    return values\n",
        "\n",
        "\n",
        "def sort_based_on(e):\n",
        "    values = e.get_objective_values()\n",
        "    return values[0]\n",
        "\n",
        "\n",
        "# sorting based on first objective value\n",
        "def sort_worse(pop):\n",
        "    pop.sort(key=sort_based_on, reverse=True)\n",
        "    return pop\n",
        "# preference sort, same as algorithm\n",
        "def preference_sort(R_T, size, objective_uncovered):\n",
        "    to_return = []\n",
        "    for objective_index in objective_uncovered:\n",
        "        min = 100\n",
        "        best = R_T[0]\n",
        "        for index in range(len(R_T)):\n",
        "            objective_values = R_T[index].get_objective_values()\n",
        "            if objective_values[objective_index] < min:\n",
        "                min = objective_values[objective_index]\n",
        "                best = R_T[index]\n",
        "        to_return.append(best)\n",
        "        R_T.remove(best)\n",
        "    if len(R_T)>0:\n",
        "        E = fast_dominating_sort(R_T, objective_uncovered)\n",
        "        for i in range(len(E)):\n",
        "            to_return.append(E[i])\n",
        "    return to_return\n",
        "\n",
        "\n",
        "# converting to numpy array (Required by library)\n",
        "def get_array_for_crowding_distance(sorted_front):\n",
        "    list = []\n",
        "    for value in sorted_front:\n",
        "        objective_values = value.get_objective_values()\n",
        "\n",
        "        np_array = numpy.array(objective_values)\n",
        "        list.append(np_array)\n",
        "\n",
        "    np_list = np.array(list)\n",
        "    cd = calc_crowding_distance(np_list)\n",
        "    return cd\n",
        "# method to assign each candidate its crownding distance\n",
        "\n",
        "def assign_crowding_distance_to_each_value(sorted_front, crowding_distance):\n",
        "    for candidate_index in range(len(sorted_front)):\n",
        "        objective_values = sorted_front[candidate_index]\n",
        "        objective_values.set_crowding_distance(crowding_distance[candidate_index])\n",
        "\n",
        "def run_search(func, initial_population, no_of_Objectives, criteria,archive,logger,start,time_budget,size,d,env, parameters , second_archive,gens):\n",
        "    global MUTATION_NUMBER\n",
        "    MUTATION_NUMBER=0\n",
        "    threshold_criteria = criteria \n",
        "    objective_uncovered = []\n",
        "    print(\"initial population \",type(initial_population),len(initial_population))\n",
        "\n",
        "    for obj in range(no_of_Objectives):\n",
        "        objective_uncovered.append(obj)  # initializing number of uncovered objective\n",
        "\n",
        "    random_population = initial_population \n",
        "\n",
        "    P_T = copy.copy(random_population)\n",
        "    evaulate_population(func, random_population ,parameters)  # evaluating whole generation and storing results propabibly its with candidates\n",
        "\n",
        "    print(random_population[0].get_objective_values())\n",
        "    update_archive(random_population, objective_uncovered, archive, no_of_Objectives,threshold_criteria)  # updating archive \n",
        "    # save initial population\n",
        "    save_all_data2(random_population,gens)\n",
        "    iteration = 0\n",
        "    #limit of number of generations \n",
        "    while iteration <10:\n",
        "        iteration = iteration + 1  # iteration count\n",
        "        #To-DO: limit by the time budget instead of the generation number\n",
        "        for arc in archive:\n",
        "            logger.info(\"***ARCHIVE***\")\n",
        "            logger.info(\"\\nValues: \" + str(\n",
        "                arc.get_candidate_values()) + \"\\nwith objective values: \" + str(\n",
        "                arc.get_objective_values()) + \"\\nSatisfying Objective: \" + str(\n",
        "                arc.get_covered_objectives()))\n",
        "        print(\"Iteration count: \" + str(iteration))\n",
        "        logger.info(\"Iteration is : \" + str(iteration))\n",
        "        logger.info(\"Number of mutations : \" + str(MUTATION_NUMBER))\n",
        "\n",
        "        R_T = []\n",
        "        \n",
        "        Q_T = generate_offspring_improved_v2(P_T,model,env,d,objective_uncovered) #generate offsprings using crossover and mutation \n",
        "\n",
        "        evaulate_population(func, Q_T, parameters)  # evaluating offspring\n",
        "        update_archive(Q_T, objective_uncovered, archive, no_of_Objectives, threshold_criteria)  # updating archive\n",
        "        save_all_data(Q_T,no_of_Objectives,threshold_criteria,second_archive)\n",
        "        # save generations\n",
        "        save_all_data2(Q_T,gens)\n",
        "        R_T = copy.deepcopy(P_T)  # R_T = P_T union Q_T\n",
        "        R_T.extend(Q_T)\n",
        "\n",
        "        F = preference_sort(R_T, size, objective_uncovered)  # Preference sorting and getting fronts\n",
        "\n",
        "        if len(objective_uncovered) == 0:  # checking if all objectives are covered\n",
        "            print(\"all_objectives_covered\")\n",
        "            logger.info(\"***Final-ARCHIVE***\")\n",
        "            print((\"***Final-ARCHIVE***\"))\n",
        "            for arc in archive:\n",
        "                print(\"\\nValues: \" + str(\n",
        "                    arc.get_candidate_values()) + \"\\nwith objective values: \" + str(\n",
        "                    arc.get_objective_values()) + \"\\nSatisfying Objective: \" + str(\n",
        "                    arc.get_covered_objectives()))\n",
        "\n",
        "                logger.info(\"\\nValues: \" + str(\n",
        "                    arc.get_candidate_values()) + \"\\nwith objective values: \" + str(\n",
        "                    arc.get_objective_values()) + \"\\nSatisfying Objective: \" + str(\n",
        "                    arc.get_covered_objectives()))\n",
        "            logger.info(\"Iteration is : \"+str(iteration))\n",
        "            logger.info(\"Number of mutations : \"+str(MUTATION_NUMBER))\n",
        "            break\n",
        "\n",
        "        P_T_1 = []  # creating next generatint PT+1\n",
        "        index = 0\n",
        "\n",
        "        while len(P_T_1) <= size:  # if length of current generation is less that size of front at top then add it\n",
        "\n",
        "            if not isinstance(F[index], Candidate):\n",
        "                if len(P_T_1) + len(F[index]) > size:\n",
        "                    break\n",
        "            else:\n",
        "                if len(P_T_1) + 1 > size:\n",
        "                    break\n",
        "\n",
        "            front = F[index]\n",
        "            if isinstance(F[index], Candidate):  # if front contains only one item\n",
        "                P_T_1.append(F[index])\n",
        "                F.remove(F[index])\n",
        "            else:\n",
        "                for ind in range(len(F[index])):  # if front have multiple items\n",
        "                    val = F[index][ind]\n",
        "                    P_T_1.append(val)\n",
        "\n",
        "                F.remove(F[index])\n",
        "        while (len(P_T_1)) < size:  # crowding distance\n",
        "            copyFront = copy.deepcopy(F[index])\n",
        "            sorted_front = sort_worse(copyFront)  # sort before crowding distance\n",
        "\n",
        "            crowding_distance = get_array_for_crowding_distance(sorted_front)  # coverting to libaray compaitble array\n",
        "            assign_crowding_distance_to_each_value(sorted_front,\n",
        "                                                   crowding_distance)  # assinging each solution its crowding distance\n",
        "            sorted_front.sort(key=sort_based_on_crowding_distance, reverse=True)  # sorting based on crowding distance\n",
        "\n",
        "            if (len(sorted_front) + len(\n",
        "                    P_T_1)) > size:  # maintaining length and adding solutions with most crowding distances\n",
        "                for sorted_front_indx in range(len(sorted_front)):\n",
        "                    candidate = sorted_front[sorted_front_indx]\n",
        "                    P_T_1.append(candidate)\n",
        "                    if len(P_T_1) >= size:\n",
        "                        break\n",
        "\n",
        "            index = index + 1\n",
        "\n",
        "        P_T_1 = P_T_1[0:size]\n",
        "        P_T = P_T_1  # assigning PT+1 to PT\n",
        "\n",
        "\n",
        "def minimize(func, population, lb, ub, no_of_Objectives, criteria,time_budget,logger,archive,size,d,env,parameters, second_archive,gens):\n",
        "    assert hasattr(func, '__call__')\n",
        "\n",
        "    start = time.time()\n",
        "    run_search(func, population, no_of_Objectives, criteria,archive,logger,start,time_budget,size,d,env ,parameters, second_archive,gens)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdT9-2cFhzhy",
        "outputId": "f64b06cf-0d1c-434f-86f1-3f07ed0c7f2c"
      },
      "outputs": [],
      "source": [
        "class CartPole_caseStudy():\n",
        "    def __init__(self):\n",
        "        logger = logging.getLogger()\n",
        "\n",
        "        now = datetime.now()\n",
        "        log_file = 'output/STARLA' + str(i) + '_V2' + str(now) + '.log'\n",
        "        logging.basicConfig(filename=log_file,\n",
        "                            format='%(asctime)s %(message)s')\n",
        "        self.parameters = [model,d,unique5]\n",
        "        logger.setLevel(logging.DEBUG)\n",
        "    def _evaluate(self,x):\n",
        "        fv = x\n",
        "        model,d,unique5 = self.parameters\n",
        "        obj1 = fitness_reward(fv)\n",
        "        obj2 = fitness_confidence(fv,model,'m')\n",
        "        binary_fv = translator(fv,model,d,unique5)\n",
        "        obj3 = fitness_functional_probability(RF_FF_1rep,binary_fv)\n",
        "        # obj4 = fitness_functional_probability(RF_RF_1rep,binary_fv)\n",
        "        to_ret = [obj1,obj2,obj3]\n",
        "        logger = logging.getLogger()\n",
        "        logger.info(str(fv)+\",\"+str(to_ret))\n",
        "        return to_ret\n",
        "\n",
        "\n",
        "def run(i,population ,archive ,second_archive, gens):\n",
        "    env=env2\n",
        "    d=1\n",
        "    size = len(population)\n",
        "    lb = [0, 0, 0]\n",
        "    ub = [100000,1000000,100000]\n",
        "\n",
        "    parameters = [model,d,unique1]\n",
        "    threshold_criteria = [70, 0.04, 0.05]\n",
        "\n",
        "\n",
        "    no_of_Objectives = 3;\n",
        "    print(\"1\",type(population),len(population))\n",
        "\n",
        "    now = datetime.now()\n",
        "    global logger\n",
        "    logger = logging.getLogger()\n",
        "    log_file = '/content/drive/MyDrive/log/STARLA' + str(i) + '_V1' + str(now) + '.log'\n",
        "    logging.basicConfig(filename=log_file,\n",
        "                        format='%(asctime)s %(message)s')\n",
        "\n",
        "    logger.setLevel(logging.DEBUG)\n",
        "\n",
        "    archive = minimize(CartPole_caseStudy()._evaluate, population, lb, ub,\n",
        "                       no_of_Objectives, threshold_criteria, 7200, \n",
        "                       logger,archive,size,d,env2 , parameters, second_archive,gens)\n",
        "    logger.info(\"Iteration completed\")\n",
        "    logger.info(\"mu\"+str(MUTATION_NUMBER))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6biTEk4Chzhy"
      },
      "source": [
        "###analyzer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEqjSa3rhzhy",
        "outputId": "711f33ac-8a42-4803-e855-296a8da2583f"
      },
      "outputs": [],
      "source": [
        "def analyze_result(result):\n",
        "  '''\n",
        "  this function is to aggrigate the differences of the results \n",
        "  :param `result`: this is the output of the re-execution-improved function\n",
        "  :return ``:\n",
        "  '''\n",
        "  total_dif =0\n",
        "  # store_diff=[]\n",
        "  for i in range(len(result)):\n",
        "    dif = abs(result[i][1][0] - result[i][1][1])\n",
        "    # store_diff.append([i,dif])\n",
        "    total_dif += dif\n",
        "  return total_dif #, store_diff\n",
        "\n",
        "\n",
        "def get_objective_distribution_and_set_candidate_objectives(population,model,d,\n",
        "                                                            unique1,RF_FF_1rep,\n",
        "                                                            RF_RF_1rep):\n",
        "  fit1_list =[]\n",
        "  fit2_list =[]\n",
        "  fit3_list =[]\n",
        "  fit4_list =[]\n",
        "  for i in range(len(population)):\n",
        "    ind_data = population[i].get_candidate_values()\n",
        "    fit1 = fitness_reward(ind_data)\n",
        "    fit2 = fitness_confidence(ind_data,model,'m')\n",
        "    binary_fv = translator(ind_data,model,d,unique1)\n",
        "    fit3 = fitness_functional_probability(RF_FF_1rep,binary_fv)\n",
        "    fit4 = fitness_reward_probability(RF_RF_1rep,binary_fv)\n",
        "    obj = [fit1,fit2,fit3,fit4]\n",
        "    population[i].set_objective_values(obj)\n",
        "    fit1_list.append(fit1)\n",
        "    fit2_list.append(fit2)\n",
        "    fit3_list.append(fit3)\n",
        "    fit4_list.append(fit4)\n",
        "  return   fit1_list, fit2_list, fit3_list, fit4_list \n",
        "\n",
        "def get_objective_distribution(population,model,d,unique1,RF_FF_1rep,RF_RF_1rep):\n",
        "  fit1_list =[]\n",
        "  fit2_list =[]\n",
        "  fit3_list =[]\n",
        "  fit4_list =[]\n",
        "  for i in range(len(population)):\n",
        "    ind_data = population[i].get_candidate_values()\n",
        "    fit1 = fitness_reward(ind_data)\n",
        "    fit2 = fitness_confidence(ind_data,model,'m')\n",
        "    binary_fv = translator(ind_data,model,d,unique1)\n",
        "    fit3 = fitness_functional_probability(RF_FF_1rep,binary_fv)\n",
        "    fit4 = fitness_reward_probability(RF_RF_1rep,binary_fv)\n",
        "    # obj = [fit1,fit2,fit3,fit4]\n",
        "    # population[i].set_objective_values(obj)\n",
        "    fit1_list.append(fit1)\n",
        "    fit2_list.append(fit2)\n",
        "    fit3_list.append(fit3)\n",
        "    fit4_list.append(fit4)\n",
        "  return   fit1_list, fit2_list, fit3_list, fit4_list \n",
        "\n",
        "\n",
        "def was_in_initial_population(solution, population,no_of_Objectives):\n",
        "  flag = False\n",
        "  for individuals_ in population:\n",
        "    if individuals_.get_objective_values() == solution.get_objective_values():\n",
        "      flag = True\n",
        "  if not flag:\n",
        "    return solution\n",
        "  if flag:\n",
        "    return 0\n",
        "\n",
        "def analyze_set_differences(differences_set):\n",
        "  '''\n",
        "  input is a set of differences \n",
        "  '''\n",
        "  analyzed_results=[]\n",
        "  for item in differences_set:\n",
        "    res = [len(item[0]),analyze_result(item[0]), item[1], len(item[0])/item[1]]\n",
        "    analyzed_results.append(res)\n",
        "  return analyzed_results\n",
        "\n",
        "def extract_differences(solution_set):\n",
        "  '''\n",
        "  input is a set of solutions like archive or second_archive \n",
        "  the output a list ([list of differences as a result of re-execution],reward)\n",
        "  '''\n",
        "  differences = []\n",
        "  for dastan in solution_set:\n",
        "    reward = dastan.get_objective_values()[0]\n",
        "    differences.append([re_execution_improved_v2(model, env2,dastan),reward])\n",
        "  return differences\n",
        "  \n",
        "def get_results_distribution(results):\n",
        "  num_of_diff=[]\n",
        "  diff_confi = []\n",
        "  diff_ration = []\n",
        "  for item in results:\n",
        "    num_of_diff.append(item[0])\n",
        "    diff_confi.append(item[1])\n",
        "    diff_ration.append(item[3])\n",
        "  return num_of_diff, diff_confi, diff_ration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WOZLRBDhzhy",
        "outputId": "a2bb68b3-00f3-4244-bde3-67d0b2ab513c"
      },
      "outputs": [],
      "source": [
        "def random_test_1(model, env, Num):\n",
        "  obs=env.reset()\n",
        "  counter = 1\n",
        "  episode_reward = 0.0\n",
        "  for i in range(Num):\n",
        "    action, _ = model.predict(obs, deterministic=True)\n",
        "    obs, reward, done, info = env.step(action)\n",
        "    episode_reward += reward\n",
        "    if done:\n",
        "      counter += 1\n",
        "      end = i\n",
        "      print(\"Reward:\", episode_reward, \"final state\", info['mem'][-2][0])\n",
        "      episode_reward = 0.0\n",
        "      obs = env.reset()\n",
        "  iter = deepcopy(counter)\n",
        "  u=1\n",
        "  while iter>1:\n",
        "    if info['mem'][-u][0]=='done':\n",
        "      lastpoint = -u\n",
        "      iter -= 1\n",
        "    u+=1\n",
        "  fin =Num - end\n",
        "  start = -Num -counter\n",
        "  randomtest = info['mem'][lastpoint:-fin]\n",
        "  ran_state = info['state'][(-counter+1):-1]\n",
        "  return randomtest , ran_state\n",
        "\n",
        "\n",
        "def random_test_2(model, env, Num):\n",
        "  obs=env.reset()\n",
        "  counter = 1\n",
        "  episode_reward = 0.0\n",
        "  for i in range(Num):\n",
        "    action, _ = model.predict(obs, deterministic=True)\n",
        "    obs, reward, done, info = env.step(action)\n",
        "    episode_reward += reward\n",
        "    if done:\n",
        "      counter += 1\n",
        "      end = i\n",
        "      episode_reward = 0.0\n",
        "      obs = env.reset()\n",
        "  iter = deepcopy(counter)\n",
        "  u=1\n",
        "  while iter>1:\n",
        "    if info['mem'][-u][0]=='done':\n",
        "      lastpoint = -u\n",
        "      iter -= 1\n",
        "    u+=1\n",
        "  fin =Num - end\n",
        "  start = -Num -counter\n",
        "  randomtest = info['mem'][lastpoint:-fin]\n",
        "  ran_state = info['state'][(-counter+1):-1]\n",
        "  return randomtest , ran_state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KA9idvgKhzhy"
      },
      "source": [
        "##Model and Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Hkrh2Ieihzhz",
        "outputId": "ec8124fe-606e-4cf4-f1b4-d07ebffba642"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/stable_baselines/common/tf_util.py:85: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/stable_baselines/common/tf_util.py:94: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/stable_baselines/deepq/dqn.py:114: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/stable_baselines/deepq/build_graph.py:355: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/stable_baselines/deepq/build_graph.py:356: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/stable_baselines/deepq/build_graph.py:139: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/stable_baselines/common/input.py:26: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/stable_baselines/deepq/policies.py:107: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/stable_baselines/deepq/build_graph.py:147: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/stable_baselines/deepq/build_graph.py:149: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/stable_baselines/deepq/build_graph.py:369: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/stable_baselines/deepq/build_graph.py:369: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/stable_baselines/deepq/build_graph.py:369: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/stable_baselines/deepq/build_graph.py:412: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/stable_baselines/deepq/build_graph.py:413: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/stable_baselines/deepq/build_graph.py:442: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/stable_baselines/a2c/utils.py:309: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/stable_baselines/common/tf_util.py:135: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/stable_baselines/common/tf_util.py:136: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "Loading a model without an environment, this model cannot be trained until it has a valid environment.\n",
            "********************** reporting the result of the model **************************\n",
            "The score for train data is 1.0\n",
            "The score for test data is 0.9928263988522238\n",
            "\n",
            "\n",
            "--------------------------------------recall---------------------------------\n",
            "the test recall for the class yes is 0.9807692307692307\n",
            "the test recall for the class no is 0.993798449612403\n",
            "the training recall for the class yes is 1.0\n",
            "the training recall for the class no is 1.0\n",
            "\n",
            "\n",
            "--------------------------------------precision------------------------------\n",
            "the test precision for the class yes is 0.9272727272727272\n",
            "the test precision for the class no is 0.9984423676012462\n",
            "the training precision for the class yes is 1.0\n",
            "the training precision for the class no is 1.0\n",
            "\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         NO        1.00      0.99      1.00       645\n",
            "         yes       0.93      0.98      0.95        52\n",
            "\n",
            "    accuracy                           0.99       697\n",
            "   macro avg       0.96      0.99      0.97       697\n",
            "weighted avg       0.99      0.99      0.99       697\n",
            "\n",
            "\n",
            "\n",
            "specifity : 0.993798449612403\n",
            "\n",
            "\n",
            "--------------------------------------confusion----------------------------\n",
            "The confusion Matrix:\n",
            "[[641   4]\n",
            " [  1  51]]\n",
            "the accuracy score in 0.9928263988522238\n",
            "\n",
            "\n",
            "********************** plotting the confusion matrix & ROC curve **************************\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "********************** reporting the result of the model **************************\n",
            "The score for train data is 1.0\n",
            "The score for test data is 0.9670014347202296\n",
            "\n",
            "\n",
            "--------------------------------------recall---------------------------------\n",
            "the test recall for the class yes is 0.9578544061302682\n",
            "the test recall for the class no is 0.9724770642201835\n",
            "the training recall for the class yes is 1.0\n",
            "the training recall for the class no is 1.0\n",
            "\n",
            "\n",
            "--------------------------------------precision------------------------------\n",
            "the test precision for the class yes is 0.9541984732824428\n",
            "the test precision for the class no is 0.9747126436781609\n",
            "the training precision for the class yes is 1.0\n",
            "the training precision for the class no is 1.0\n",
            "\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         NO        0.97      0.97      0.97       436\n",
            "         yes       0.95      0.96      0.96       261\n",
            "\n",
            "    accuracy                           0.97       697\n",
            "   macro avg       0.96      0.97      0.96       697\n",
            "weighted avg       0.97      0.97      0.97       697\n",
            "\n",
            "\n",
            "\n",
            "specifity : 0.9724770642201835\n",
            "\n",
            "\n",
            "--------------------------------------confusion----------------------------\n",
            "The confusion Matrix:\n",
            "[[424  12]\n",
            " [ 11 250]]\n",
            "the accuracy score in 0.9670014347202296\n",
            "\n",
            "\n",
            "********************** plotting the confusion matrix & ROC curve **************************\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 2min 28s (started: 2022-05-30 21:19:35 +00:00)\n"
          ]
        }
      ],
      "source": [
        "#Address of the trained RL model \n",
        "Drive_model  =\"/content/drive/MyDrive/GM/dqn-cartpole-50000-with127-GA-Mut-2.pkl\"\n",
        "\n",
        "\n",
        "env2 = gym.make('CartPole-v1')\n",
        "env2 = StoreWrapper(env2)\n",
        "model = DQN('MlpPolicy',env=env2, verbose=1)\n",
        "model = model.load(Drive_model)\n",
        "#########################################################  Read DATA and Load Model #############\n",
        "\n",
        "ep = []\n",
        "buffer = []\n",
        "line = 0\n",
        "#Address of data of RL \n",
        "##changing the shape of the episodes when we are reading the data\n",
        "file = \"/content/drive/MyDrive/GM/dict_GA_Mut_10-09-2020.csv\"\n",
        "with open(file, 'r' ) as read_obj:\n",
        "    csv_reader = reader(read_obj)\n",
        "    for row in csv_reader:\n",
        "        if row[0] == 'done':\n",
        "          buffer.append([row[0],float(row[1])])\n",
        "          ep.append(buffer)\n",
        "          buffer = []\n",
        "          line+=1\n",
        "        else:\n",
        "          ro = row[0][1:-1]\n",
        "          r = [float(i) for i in ro.split()]\n",
        "          buffer.append([r,row[1]])\n",
        "\n",
        "\n",
        "\n",
        "######################################################### Read abstract classes #############\n",
        "# /content/drive/MyDrive/GM/Abstract_unique1_for_d=1.pickle\n",
        "# data of abstract classes\n",
        "\n",
        "Read_from_data = True\n",
        "d=1\n",
        "\n",
        "if Read_from_data:\n",
        "  with open(f'/content/drive/MyDrive/GM/Abstract_unique1_for_d=1.pickle', 'rb') as file2:\n",
        "      unique1 = pickle.load(file2)\n",
        "  uni1=np.array(unique1)\n",
        "  unique5 = unique1\n",
        "if not Read_from_data:\n",
        "  unique1,uni1 = Abstract_classes(ep,d,model)\n",
        "  unique5 = unique1\n",
        "\n",
        "\n",
        "epsilon = 0.05\n",
        "data1_x_b, data1_y_b, data1_y_f_b = ML_first_representation(d,epsilon,uni1,model,ep,unique1)\n",
        "\n",
        "#########################################################  Train ML -  Reward fault predictor  #############\n",
        "\n",
        "X_train_reward_fault, X_test_reward_fault, y_train_reward_fault, y_test_reward_fault = train_test_split(data1_x_b, data1_y_b, test_size=0.33, random_state=42)\n",
        "\n",
        "RF_RF_1rep = RandomForestClassifier(random_state=0, class_weight='balanced')\n",
        "RF_RF_1rep.fit(X_train_reward_fault,y_train_reward_fault)\n",
        "report(RF_RF_1rep,X_train_reward_fault,y_train_reward_fault,X_test_reward_fault,y_test_reward_fault)\n",
        "\n",
        "#########################################################  Train ML - Functional fault predictor #############\n",
        "\n",
        "\n",
        "X_train_f, X_test_f, y_train_f, y_test_f = train_test_split(data1_x_b, data1_y_f_b, test_size=0.33, random_state=42)\n",
        "RF_FF_1rep = RandomForestClassifier(random_state=0, class_weight='balanced')\n",
        "RF_FF_1rep.fit(X_train_f,y_train_f)\n",
        "report(RF_FF_1rep,X_train_f,y_train_f,X_test_f,y_test_f)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6q3uQXQatq2w"
      },
      "source": [
        "#Re-execution functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCjdJSQw4D9l",
        "outputId": "2db11098-3692-4e9d-8e87-360740a056cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 29 ms (started: 2022-05-20 16:18:00 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def re_execute_final_ff_v1_woprint(model,env,candidate):\n",
        "  differences=[]\n",
        "  episode_limit = 200 \n",
        "  env.reset()\n",
        "  obs =env.set_state(candidate.get_start_state()) \n",
        "  episode = candidate.get_candidate_values()\n",
        "  episode_reward = 0.0\n",
        "  done =False\n",
        "  diviate_counter = 0\n",
        "  divs=[]\n",
        "  ff=False\n",
        "  for i in range(episode_limit):\n",
        "    if done:\n",
        "      if abs(obs[0])>=(2.4-epsilon):\n",
        "          ff = True\n",
        "      return differences ,divs, ff\n",
        "    if i >=(len(episode)-1):\n",
        "      action, _ = model.predict(obs, deterministic=True)\n",
        "      obs, reward, done, info = env.step(int(action)) \n",
        "      if done:\n",
        "        if abs(obs[0])>=(2.4-epsilon):\n",
        "          ff = True\n",
        "        return differences ,divs , ff\n",
        "      continue\n",
        "    action, _ = model.predict(obs, deterministic=True)\n",
        "    action1, _ = model.predict(episode[i][0], deterministic=True)\n",
        "    if action != int(episode[i][1]) and action1 != int(episode[i][1]):\n",
        "      prob=model.action_probability(episode[i][0])\n",
        "      differences.append([i , prob])\n",
        "    if action != int(episode[i][1]):\n",
        "      diviate_counter+=1\n",
        "      prob=model.action_probability(episode[i][0])\n",
        "      divs.append([i , prob])\n",
        "\n",
        "    obs, reward, done, info = env.step(int(action)) \n",
        "    episode_reward += reward\n",
        "  if abs(obs[0])>=(2.4-epsilon):\n",
        "    ff = True\n",
        "  assert done , \"not finished in 200 steps \"\n",
        "  return differences ,divs , ff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MbQ_r2I7g4U"
      },
      "source": [
        "#Run Re-execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0MmUzZd7ims",
        "outputId": "38f5b34b-5f4f-4ff3-8976-73c499a16af4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run0_0.pickle\n",
            "In generation  1\n",
            "Number of estimated functional faults: 490\n",
            "Number of reward faults: 3\n",
            "Number of non-faults: 1001\n",
            "\n",
            "\n",
            "In generation  2\n",
            "Number of estimated functional faults: 555\n",
            "Number of reward faults: 3\n",
            "Number of non-faults: 931\n",
            "\n",
            "\n",
            "In generation  3\n",
            "Number of estimated functional faults: 600\n",
            "Number of reward faults: 8\n",
            "Number of non-faults: 897\n",
            "\n",
            "\n",
            "In generation  4\n",
            "Number of estimated functional faults: 638\n",
            "Number of reward faults: 9\n",
            "Number of non-faults: 854\n",
            "\n",
            "\n",
            "In generation  5\n",
            "Number of estimated functional faults: 623\n",
            "Number of reward faults: 8\n",
            "Number of non-faults: 870\n",
            "\n",
            "\n",
            "In generation  6\n",
            "Number of estimated functional faults: 649\n",
            "Number of reward faults: 9\n",
            "Number of non-faults: 854\n",
            "\n",
            "\n",
            "In generation  7\n",
            "Number of estimated functional faults: 614\n",
            "Number of reward faults: 6\n",
            "Number of non-faults: 877\n",
            "\n",
            "\n",
            "In generation  8\n",
            "Number of estimated functional faults: 609\n",
            "Number of reward faults: 17\n",
            "Number of non-faults: 885\n",
            "\n",
            "\n",
            "In generation  9\n",
            "Number of estimated functional faults: 594\n",
            "Number of reward faults: 18\n",
            "Number of non-faults: 877\n",
            "\n",
            "\n",
            "In generation  10\n",
            "Number of estimated functional faults: 564\n",
            "Number of reward faults: 28\n",
            "Number of non-faults: 901\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run0_0.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run1_0.pickle\n",
            "In generation  1\n",
            "Number of estimated functional faults: 458\n",
            "Number of reward faults: 5\n",
            "Number of non-faults: 1019\n",
            "\n",
            "\n",
            "In generation  2\n",
            "Number of estimated functional faults: 585\n",
            "Number of reward faults: 3\n",
            "Number of non-faults: 898\n",
            "\n",
            "\n",
            "In generation  3\n",
            "Number of estimated functional faults: 617\n",
            "Number of reward faults: 4\n",
            "Number of non-faults: 853\n",
            "\n",
            "\n",
            "In generation  4\n",
            "Number of estimated functional faults: 690\n",
            "Number of reward faults: 2\n",
            "Number of non-faults: 789\n",
            "\n",
            "\n",
            "In generation  5\n",
            "Number of estimated functional faults: 643\n",
            "Number of reward faults: 7\n",
            "Number of non-faults: 845\n",
            "\n",
            "\n",
            "In generation  6\n",
            "Number of estimated functional faults: 701\n",
            "Number of reward faults: 11\n",
            "Number of non-faults: 802\n",
            "\n",
            "\n",
            "In generation  7\n",
            "Number of estimated functional faults: 659\n",
            "Number of reward faults: 12\n",
            "Number of non-faults: 846\n",
            "\n",
            "\n",
            "In generation  8\n",
            "Number of estimated functional faults: 581\n",
            "Number of reward faults: 18\n",
            "Number of non-faults: 909\n",
            "\n",
            "\n",
            "In generation  9\n",
            "Number of estimated functional faults: 566\n",
            "Number of reward faults: 20\n",
            "Number of non-faults: 904\n",
            "\n",
            "\n",
            "In generation  10\n",
            "Number of estimated functional faults: 586\n",
            "Number of reward faults: 21\n",
            "Number of non-faults: 935\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run1_0.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run1_1.pickle\n",
            "In generation  1\n",
            "Number of estimated functional faults: 478\n",
            "Number of reward faults: 3\n",
            "Number of non-faults: 1004\n",
            "\n",
            "\n",
            "In generation  2\n",
            "Number of estimated functional faults: 585\n",
            "Number of reward faults: 3\n",
            "Number of non-faults: 901\n",
            "\n",
            "\n",
            "In generation  3\n",
            "Number of estimated functional faults: 611\n",
            "Number of reward faults: 2\n",
            "Number of non-faults: 856\n",
            "\n",
            "\n",
            "In generation  4\n",
            "Number of estimated functional faults: 657\n",
            "Number of reward faults: 7\n",
            "Number of non-faults: 817\n",
            "\n",
            "\n",
            "In generation  5\n",
            "Number of estimated functional faults: 645\n",
            "Number of reward faults: 9\n",
            "Number of non-faults: 822\n",
            "\n",
            "\n",
            "In generation  6\n",
            "Number of estimated functional faults: 660\n",
            "Number of reward faults: 10\n",
            "Number of non-faults: 793\n",
            "\n",
            "\n",
            "In generation  7\n",
            "Number of estimated functional faults: 619\n",
            "Number of reward faults: 13\n",
            "Number of non-faults: 847\n",
            "\n",
            "\n",
            "In generation  8\n",
            "Number of estimated functional faults: 643\n",
            "Number of reward faults: 11\n",
            "Number of non-faults: 824\n",
            "\n",
            "\n",
            "In generation  9\n",
            "Number of estimated functional faults: 614\n",
            "Number of reward faults: 31\n",
            "Number of non-faults: 828\n",
            "\n",
            "\n",
            "In generation  10\n",
            "Number of estimated functional faults: 609\n",
            "Number of reward faults: 41\n",
            "Number of non-faults: 818\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run1_1.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run1_2.pickle\n",
            "In generation  1\n",
            "Number of estimated functional faults: 467\n",
            "Number of reward faults: 4\n",
            "Number of non-faults: 1019\n",
            "\n",
            "\n",
            "In generation  2\n",
            "Number of estimated functional faults: 620\n",
            "Number of reward faults: 6\n",
            "Number of non-faults: 873\n",
            "\n",
            "\n",
            "In generation  3\n",
            "Number of estimated functional faults: 651\n",
            "Number of reward faults: 2\n",
            "Number of non-faults: 839\n",
            "\n",
            "\n",
            "In generation  4\n",
            "Number of estimated functional faults: 651\n",
            "Number of reward faults: 9\n",
            "Number of non-faults: 833\n",
            "\n",
            "\n",
            "In generation  5\n",
            "Number of estimated functional faults: 674\n",
            "Number of reward faults: 10\n",
            "Number of non-faults: 819\n",
            "\n",
            "\n",
            "In generation  6\n",
            "Number of estimated functional faults: 687\n",
            "Number of reward faults: 8\n",
            "Number of non-faults: 816\n",
            "\n",
            "\n",
            "In generation  7\n",
            "Number of estimated functional faults: 637\n",
            "Number of reward faults: 7\n",
            "Number of non-faults: 864\n",
            "\n",
            "\n",
            "In generation  8\n",
            "Number of estimated functional faults: 612\n",
            "Number of reward faults: 14\n",
            "Number of non-faults: 896\n",
            "\n",
            "\n",
            "In generation  9\n",
            "Number of estimated functional faults: 617\n",
            "Number of reward faults: 19\n",
            "Number of non-faults: 930\n",
            "\n",
            "\n",
            "In generation  10\n",
            "Number of estimated functional faults: 611\n",
            "Number of reward faults: 27\n",
            "Number of non-faults: 907\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run1_2.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run1_3.pickle\n",
            "In generation  1\n",
            "Number of estimated functional faults: 551\n",
            "Number of reward faults: 1\n",
            "Number of non-faults: 944\n",
            "\n",
            "\n",
            "In generation  2\n",
            "Number of estimated functional faults: 654\n",
            "Number of reward faults: 0\n",
            "Number of non-faults: 846\n",
            "\n",
            "\n",
            "In generation  3\n",
            "Number of estimated functional faults: 665\n",
            "Number of reward faults: 3\n",
            "Number of non-faults: 834\n",
            "\n",
            "\n",
            "In generation  4\n",
            "Number of estimated functional faults: 680\n",
            "Number of reward faults: 4\n",
            "Number of non-faults: 808\n",
            "\n",
            "\n",
            "In generation  5\n",
            "Number of estimated functional faults: 703\n",
            "Number of reward faults: 6\n",
            "Number of non-faults: 793\n",
            "\n",
            "\n",
            "In generation  6\n",
            "Number of estimated functional faults: 714\n",
            "Number of reward faults: 11\n",
            "Number of non-faults: 781\n",
            "\n",
            "\n",
            "In generation  7\n",
            "Number of estimated functional faults: 669\n",
            "Number of reward faults: 12\n",
            "Number of non-faults: 801\n",
            "\n",
            "\n",
            "In generation  8\n",
            "Number of estimated functional faults: 651\n",
            "Number of reward faults: 11\n",
            "Number of non-faults: 822\n",
            "\n",
            "\n",
            "In generation  9\n",
            "Number of estimated functional faults: 610\n",
            "Number of reward faults: 19\n",
            "Number of non-faults: 847\n",
            "\n",
            "\n",
            "In generation  10\n",
            "Number of estimated functional faults: 617\n",
            "Number of reward faults: 22\n",
            "Number of non-faults: 854\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run1_3.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run2_0.pickle\n",
            "In generation  1\n",
            "Number of estimated functional faults: 490\n",
            "Number of reward faults: 1\n",
            "Number of non-faults: 999\n",
            "\n",
            "\n",
            "In generation  2\n",
            "Number of estimated functional faults: 619\n",
            "Number of reward faults: 5\n",
            "Number of non-faults: 866\n",
            "\n",
            "\n",
            "In generation  3\n",
            "Number of estimated functional faults: 664\n",
            "Number of reward faults: 4\n",
            "Number of non-faults: 813\n",
            "\n",
            "\n",
            "In generation  4\n",
            "Number of estimated functional faults: 676\n",
            "Number of reward faults: 4\n",
            "Number of non-faults: 793\n",
            "\n",
            "\n",
            "In generation  5\n",
            "Number of estimated functional faults: 724\n",
            "Number of reward faults: 13\n",
            "Number of non-faults: 761\n",
            "\n",
            "\n",
            "In generation  6\n",
            "Number of estimated functional faults: 672\n",
            "Number of reward faults: 11\n",
            "Number of non-faults: 803\n",
            "\n",
            "\n",
            "In generation  7\n",
            "Number of estimated functional faults: 678\n",
            "Number of reward faults: 15\n",
            "Number of non-faults: 815\n",
            "\n",
            "\n",
            "In generation  8\n",
            "Number of estimated functional faults: 676\n",
            "Number of reward faults: 18\n",
            "Number of non-faults: 809\n",
            "\n",
            "\n",
            "In generation  9\n",
            "Number of estimated functional faults: 643\n",
            "Number of reward faults: 23\n",
            "Number of non-faults: 840\n",
            "\n",
            "\n",
            "In generation  10\n",
            "Number of estimated functional faults: 564\n",
            "Number of reward faults: 37\n",
            "Number of non-faults: 900\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run2_0.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run2_1.pickle\n",
            "In generation  1\n",
            "Number of estimated functional faults: 496\n",
            "Number of reward faults: 3\n",
            "Number of non-faults: 989\n",
            "\n",
            "\n",
            "In generation  2\n",
            "Number of estimated functional faults: 562\n",
            "Number of reward faults: 6\n",
            "Number of non-faults: 924\n",
            "\n",
            "\n",
            "In generation  3\n",
            "Number of estimated functional faults: 645\n",
            "Number of reward faults: 9\n",
            "Number of non-faults: 838\n",
            "\n",
            "\n",
            "In generation  4\n",
            "Number of estimated functional faults: 623\n",
            "Number of reward faults: 10\n",
            "Number of non-faults: 848\n",
            "\n",
            "\n",
            "In generation  5\n",
            "Number of estimated functional faults: 669\n",
            "Number of reward faults: 14\n",
            "Number of non-faults: 795\n",
            "\n",
            "\n",
            "In generation  6\n",
            "Number of estimated functional faults: 626\n",
            "Number of reward faults: 12\n",
            "Number of non-faults: 836\n",
            "\n",
            "\n",
            "In generation  7\n",
            "Number of estimated functional faults: 652\n",
            "Number of reward faults: 14\n",
            "Number of non-faults: 821\n",
            "\n",
            "\n",
            "In generation  8\n",
            "Number of estimated functional faults: 628\n",
            "Number of reward faults: 18\n",
            "Number of non-faults: 835\n",
            "\n",
            "\n",
            "In generation  9\n",
            "Number of estimated functional faults: 623\n",
            "Number of reward faults: 26\n",
            "Number of non-faults: 832\n",
            "\n",
            "\n",
            "In generation  10\n",
            "Number of estimated functional faults: 593\n",
            "Number of reward faults: 36\n",
            "Number of non-faults: 832\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run2_1.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run2_2.pickle\n",
            "In generation  1\n",
            "Number of estimated functional faults: 447\n",
            "Number of reward faults: 6\n",
            "Number of non-faults: 1036\n",
            "\n",
            "\n",
            "In generation  2\n",
            "Number of estimated functional faults: 549\n",
            "Number of reward faults: 6\n",
            "Number of non-faults: 936\n",
            "\n",
            "\n",
            "In generation  3\n",
            "Number of estimated functional faults: 589\n",
            "Number of reward faults: 4\n",
            "Number of non-faults: 899\n",
            "\n",
            "\n",
            "In generation  4\n",
            "Number of estimated functional faults: 610\n",
            "Number of reward faults: 10\n",
            "Number of non-faults: 867\n",
            "\n",
            "\n",
            "In generation  5\n",
            "Number of estimated functional faults: 675\n",
            "Number of reward faults: 14\n",
            "Number of non-faults: 806\n",
            "\n",
            "\n",
            "In generation  6\n",
            "Number of estimated functional faults: 655\n",
            "Number of reward faults: 9\n",
            "Number of non-faults: 830\n",
            "\n",
            "\n",
            "In generation  7\n",
            "Number of estimated functional faults: 678\n",
            "Number of reward faults: 16\n",
            "Number of non-faults: 790\n",
            "\n",
            "\n",
            "In generation  8\n",
            "Number of estimated functional faults: 674\n",
            "Number of reward faults: 15\n",
            "Number of non-faults: 785\n",
            "\n",
            "\n",
            "In generation  9\n",
            "Number of estimated functional faults: 666\n",
            "Number of reward faults: 25\n",
            "Number of non-faults: 775\n",
            "\n",
            "\n",
            "In generation  10\n",
            "Number of estimated functional faults: 605\n",
            "Number of reward faults: 37\n",
            "Number of non-faults: 818\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run2_2.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run2_3.pickle\n",
            "In generation  1\n",
            "Number of estimated functional faults: 491\n",
            "Number of reward faults: 2\n",
            "Number of non-faults: 997\n",
            "\n",
            "\n",
            "In generation  2\n",
            "Number of estimated functional faults: 607\n",
            "Number of reward faults: 0\n",
            "Number of non-faults: 885\n",
            "\n",
            "\n",
            "In generation  3\n",
            "Number of estimated functional faults: 673\n",
            "Number of reward faults: 5\n",
            "Number of non-faults: 819\n",
            "\n",
            "\n",
            "In generation  4\n",
            "Number of estimated functional faults: 726\n",
            "Number of reward faults: 3\n",
            "Number of non-faults: 780\n",
            "\n",
            "\n",
            "In generation  5\n",
            "Number of estimated functional faults: 704\n",
            "Number of reward faults: 7\n",
            "Number of non-faults: 800\n",
            "\n",
            "\n",
            "In generation  6\n",
            "Number of estimated functional faults: 664\n",
            "Number of reward faults: 9\n",
            "Number of non-faults: 839\n",
            "\n",
            "\n",
            "In generation  7\n",
            "Number of estimated functional faults: 693\n",
            "Number of reward faults: 4\n",
            "Number of non-faults: 824\n",
            "\n",
            "\n",
            "In generation  8\n",
            "Number of estimated functional faults: 666\n",
            "Number of reward faults: 13\n",
            "Number of non-faults: 838\n",
            "\n",
            "\n",
            "In generation  9\n",
            "Number of estimated functional faults: 640\n",
            "Number of reward faults: 15\n",
            "Number of non-faults: 858\n",
            "\n",
            "\n",
            "In generation  10\n",
            "Number of estimated functional faults: 662\n",
            "Number of reward faults: 22\n",
            "Number of non-faults: 850\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run2_3.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run2_4.pickle\n",
            "In generation  1\n",
            "Number of estimated functional faults: 473\n",
            "Number of reward faults: 0\n",
            "Number of non-faults: 1020\n",
            "\n",
            "\n",
            "In generation  2\n",
            "Number of estimated functional faults: 546\n",
            "Number of reward faults: 3\n",
            "Number of non-faults: 951\n",
            "\n",
            "\n",
            "In generation  3\n",
            "Number of estimated functional faults: 606\n",
            "Number of reward faults: 7\n",
            "Number of non-faults: 892\n",
            "\n",
            "\n",
            "In generation  4\n",
            "Number of estimated functional faults: 675\n",
            "Number of reward faults: 4\n",
            "Number of non-faults: 831\n",
            "\n",
            "\n",
            "In generation  5\n",
            "Number of estimated functional faults: 661\n",
            "Number of reward faults: 14\n",
            "Number of non-faults: 836\n",
            "\n",
            "\n",
            "In generation  6\n",
            "Number of estimated functional faults: 675\n",
            "Number of reward faults: 3\n",
            "Number of non-faults: 828\n",
            "\n",
            "\n",
            "In generation  7\n",
            "Number of estimated functional faults: 648\n",
            "Number of reward faults: 16\n",
            "Number of non-faults: 825\n",
            "\n",
            "\n",
            "In generation  8\n",
            "Number of estimated functional faults: 621\n",
            "Number of reward faults: 14\n",
            "Number of non-faults: 852\n",
            "\n",
            "\n",
            "In generation  9\n",
            "Number of estimated functional faults: 607\n",
            "Number of reward faults: 22\n",
            "Number of non-faults: 855\n",
            "\n",
            "\n",
            "In generation  10\n",
            "Number of estimated functional faults: 590\n",
            "Number of reward faults: 33\n",
            "Number of non-faults: 845\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run2_4.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run3_0.pickle\n",
            "In generation  1\n",
            "Number of estimated functional faults: 506\n",
            "Number of reward faults: 2\n",
            "Number of non-faults: 989\n",
            "\n",
            "\n",
            "In generation  2\n",
            "Number of estimated functional faults: 604\n",
            "Number of reward faults: 5\n",
            "Number of non-faults: 887\n",
            "\n",
            "\n",
            "In generation  3\n",
            "Number of estimated functional faults: 638\n",
            "Number of reward faults: 6\n",
            "Number of non-faults: 870\n",
            "\n",
            "\n",
            "In generation  4\n",
            "Number of estimated functional faults: 708\n",
            "Number of reward faults: 10\n",
            "Number of non-faults: 798\n",
            "\n",
            "\n",
            "In generation  5\n",
            "Number of estimated functional faults: 701\n",
            "Number of reward faults: 6\n",
            "Number of non-faults: 816\n",
            "\n",
            "\n",
            "In generation  6\n",
            "Number of estimated functional faults: 692\n",
            "Number of reward faults: 9\n",
            "Number of non-faults: 817\n",
            "\n",
            "\n",
            "In generation  7\n",
            "Number of estimated functional faults: 708\n",
            "Number of reward faults: 14\n",
            "Number of non-faults: 798\n",
            "\n",
            "\n",
            "In generation  8\n",
            "Number of estimated functional faults: 673\n",
            "Number of reward faults: 19\n",
            "Number of non-faults: 839\n",
            "\n",
            "\n",
            "In generation  9\n",
            "Number of estimated functional faults: 679\n",
            "Number of reward faults: 27\n",
            "Number of non-faults: 840\n",
            "\n",
            "\n",
            "In generation  10\n",
            "Number of estimated functional faults: 649\n",
            "Number of reward faults: 40\n",
            "Number of non-faults: 834\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run3_0.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run3_1.pickle\n",
            "In generation  1\n",
            "Number of estimated functional faults: 488\n",
            "Number of reward faults: 0\n",
            "Number of non-faults: 1003\n",
            "\n",
            "\n",
            "In generation  2\n",
            "Number of estimated functional faults: 529\n",
            "Number of reward faults: 2\n",
            "Number of non-faults: 975\n",
            "\n",
            "\n",
            "In generation  3\n",
            "Number of estimated functional faults: 651\n",
            "Number of reward faults: 4\n",
            "Number of non-faults: 845\n",
            "\n",
            "\n",
            "In generation  4\n",
            "Number of estimated functional faults: 659\n",
            "Number of reward faults: 6\n",
            "Number of non-faults: 831\n",
            "\n",
            "\n",
            "In generation  5\n",
            "Number of estimated functional faults: 670\n",
            "Number of reward faults: 7\n",
            "Number of non-faults: 837\n",
            "\n",
            "\n",
            "In generation  6\n",
            "Number of estimated functional faults: 670\n",
            "Number of reward faults: 7\n",
            "Number of non-faults: 858\n",
            "\n",
            "\n",
            "In generation  7\n",
            "Number of estimated functional faults: 697\n",
            "Number of reward faults: 8\n",
            "Number of non-faults: 828\n",
            "\n",
            "\n",
            "In generation  8\n",
            "Number of estimated functional faults: 671\n",
            "Number of reward faults: 9\n",
            "Number of non-faults: 880\n",
            "\n",
            "\n",
            "In generation  9\n",
            "Number of estimated functional faults: 653\n",
            "Number of reward faults: 17\n",
            "Number of non-faults: 901\n",
            "\n",
            "\n",
            "In generation  10\n",
            "Number of estimated functional faults: 597\n",
            "Number of reward faults: 23\n",
            "Number of non-faults: 952\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run3_1.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run3_2.pickle\n",
            "In generation  1\n",
            "Number of estimated functional faults: 479\n",
            "Number of reward faults: 1\n",
            "Number of non-faults: 1011\n",
            "\n",
            "\n",
            "In generation  2\n",
            "Number of estimated functional faults: 601\n",
            "Number of reward faults: 4\n",
            "Number of non-faults: 889\n",
            "\n",
            "\n",
            "In generation  3\n",
            "Number of estimated functional faults: 662\n",
            "Number of reward faults: 6\n",
            "Number of non-faults: 819\n",
            "\n",
            "\n",
            "In generation  4\n",
            "Number of estimated functional faults: 628\n",
            "Number of reward faults: 6\n",
            "Number of non-faults: 840\n",
            "\n",
            "\n",
            "In generation  5\n",
            "Number of estimated functional faults: 655\n",
            "Number of reward faults: 7\n",
            "Number of non-faults: 823\n",
            "\n",
            "\n",
            "In generation  6\n",
            "Number of estimated functional faults: 643\n",
            "Number of reward faults: 9\n",
            "Number of non-faults: 814\n",
            "\n",
            "\n",
            "In generation  7\n",
            "Number of estimated functional faults: 598\n",
            "Number of reward faults: 7\n",
            "Number of non-faults: 855\n",
            "\n",
            "\n",
            "In generation  8\n",
            "Number of estimated functional faults: 581\n",
            "Number of reward faults: 14\n",
            "Number of non-faults: 876\n",
            "\n",
            "\n",
            "In generation  9\n",
            "Number of estimated functional faults: 573\n",
            "Number of reward faults: 23\n",
            "Number of non-faults: 881\n",
            "\n",
            "\n",
            "In generation  10\n",
            "Number of estimated functional faults: 547\n",
            "Number of reward faults: 28\n",
            "Number of non-faults: 887\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run3_2.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run3_3.pickle\n",
            "In generation  1\n",
            "Number of estimated functional faults: 539\n",
            "Number of reward faults: 0\n",
            "Number of non-faults: 952\n",
            "\n",
            "\n",
            "In generation  2\n",
            "Number of estimated functional faults: 596\n",
            "Number of reward faults: 2\n",
            "Number of non-faults: 878\n",
            "\n",
            "\n",
            "In generation  3\n",
            "Number of estimated functional faults: 606\n",
            "Number of reward faults: 4\n",
            "Number of non-faults: 865\n",
            "\n",
            "\n",
            "In generation  4\n",
            "Number of estimated functional faults: 672\n",
            "Number of reward faults: 11\n",
            "Number of non-faults: 796\n",
            "\n",
            "\n",
            "In generation  5\n",
            "Number of estimated functional faults: 662\n",
            "Number of reward faults: 4\n",
            "Number of non-faults: 824\n",
            "\n",
            "\n",
            "In generation  6\n",
            "Number of estimated functional faults: 672\n",
            "Number of reward faults: 6\n",
            "Number of non-faults: 805\n",
            "\n",
            "\n",
            "In generation  7\n",
            "Number of estimated functional faults: 651\n",
            "Number of reward faults: 9\n",
            "Number of non-faults: 831\n",
            "\n",
            "\n",
            "In generation  8\n",
            "Number of estimated functional faults: 615\n",
            "Number of reward faults: 13\n",
            "Number of non-faults: 862\n",
            "\n",
            "\n",
            "In generation  9\n",
            "Number of estimated functional faults: 645\n",
            "Number of reward faults: 18\n",
            "Number of non-faults: 816\n",
            "\n",
            "\n",
            "In generation  10\n",
            "Number of estimated functional faults: 564\n",
            "Number of reward faults: 24\n",
            "Number of non-faults: 878\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run3_3.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run3_4.pickle\n",
            "In generation  1\n",
            "Number of estimated functional faults: 550\n",
            "Number of reward faults: 3\n",
            "Number of non-faults: 938\n",
            "\n",
            "\n",
            "In generation  2\n",
            "Number of estimated functional faults: 590\n",
            "Number of reward faults: 4\n",
            "Number of non-faults: 885\n",
            "\n",
            "\n",
            "In generation  3\n",
            "Number of estimated functional faults: 647\n",
            "Number of reward faults: 5\n",
            "Number of non-faults: 830\n",
            "\n",
            "\n",
            "In generation  4\n",
            "Number of estimated functional faults: 663\n",
            "Number of reward faults: 6\n",
            "Number of non-faults: 815\n",
            "\n",
            "\n",
            "In generation  5\n",
            "Number of estimated functional faults: 681\n",
            "Number of reward faults: 8\n",
            "Number of non-faults: 779\n",
            "\n",
            "\n",
            "In generation  6\n",
            "Number of estimated functional faults: 643\n",
            "Number of reward faults: 17\n",
            "Number of non-faults: 800\n",
            "\n",
            "\n",
            "In generation  7\n",
            "Number of estimated functional faults: 628\n",
            "Number of reward faults: 14\n",
            "Number of non-faults: 822\n",
            "\n",
            "\n",
            "In generation  8\n",
            "Number of estimated functional faults: 604\n",
            "Number of reward faults: 20\n",
            "Number of non-faults: 854\n",
            "\n",
            "\n",
            "In generation  9\n",
            "Number of estimated functional faults: 524\n",
            "Number of reward faults: 28\n",
            "Number of non-faults: 900\n",
            "\n",
            "\n",
            "In generation  10\n",
            "Number of estimated functional faults: 519\n",
            "Number of reward faults: 35\n",
            "Number of non-faults: 912\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run3_4.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run3_5.pickle\n",
            "In generation  1\n",
            "Number of estimated functional faults: 536\n",
            "Number of reward faults: 2\n",
            "Number of non-faults: 952\n",
            "\n",
            "\n",
            "In generation  2\n",
            "Number of estimated functional faults: 639\n",
            "Number of reward faults: 3\n",
            "Number of non-faults: 853\n",
            "\n",
            "\n",
            "In generation  3\n",
            "Number of estimated functional faults: 660\n",
            "Number of reward faults: 8\n",
            "Number of non-faults: 825\n",
            "\n",
            "\n",
            "In generation  4\n",
            "Number of estimated functional faults: 716\n",
            "Number of reward faults: 8\n",
            "Number of non-faults: 781\n",
            "\n",
            "\n",
            "In generation  5\n",
            "Number of estimated functional faults: 678\n",
            "Number of reward faults: 9\n",
            "Number of non-faults: 819\n",
            "\n",
            "\n",
            "In generation  6\n",
            "Number of estimated functional faults: 697\n",
            "Number of reward faults: 14\n",
            "Number of non-faults: 803\n",
            "\n",
            "\n",
            "In generation  7\n",
            "Number of estimated functional faults: 732\n",
            "Number of reward faults: 11\n",
            "Number of non-faults: 761\n",
            "\n",
            "\n",
            "In generation  8\n",
            "Number of estimated functional faults: 660\n",
            "Number of reward faults: 24\n",
            "Number of non-faults: 803\n",
            "\n",
            "\n",
            "In generation  9\n",
            "Number of estimated functional faults: 680\n",
            "Number of reward faults: 31\n",
            "Number of non-faults: 802\n",
            "\n",
            "\n",
            "In generation  10\n",
            "Number of estimated functional faults: 669\n",
            "Number of reward faults: 41\n",
            "Number of non-faults: 814\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run3_5.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run4_0.pickle\n",
            "In generation  1\n",
            "Number of estimated functional faults: 493\n",
            "Number of reward faults: 2\n",
            "Number of non-faults: 994\n",
            "\n",
            "\n",
            "In generation  2\n",
            "Number of estimated functional faults: 600\n",
            "Number of reward faults: 7\n",
            "Number of non-faults: 868\n",
            "\n",
            "\n",
            "In generation  3\n",
            "Number of estimated functional faults: 659\n",
            "Number of reward faults: 8\n",
            "Number of non-faults: 809\n",
            "\n",
            "\n",
            "In generation  4\n",
            "Number of estimated functional faults: 645\n",
            "Number of reward faults: 7\n",
            "Number of non-faults: 810\n",
            "\n",
            "\n",
            "In generation  5\n",
            "Number of estimated functional faults: 671\n",
            "Number of reward faults: 11\n",
            "Number of non-faults: 784\n",
            "\n",
            "\n",
            "In generation  6\n",
            "Number of estimated functional faults: 724\n",
            "Number of reward faults: 8\n",
            "Number of non-faults: 725\n",
            "\n",
            "\n",
            "In generation  7\n",
            "Number of estimated functional faults: 679\n",
            "Number of reward faults: 11\n",
            "Number of non-faults: 776\n",
            "\n",
            "\n",
            "In generation  8\n",
            "Number of estimated functional faults: 626\n",
            "Number of reward faults: 13\n",
            "Number of non-faults: 825\n",
            "\n",
            "\n",
            "In generation  9\n",
            "Number of estimated functional faults: 590\n",
            "Number of reward faults: 26\n",
            "Number of non-faults: 832\n",
            "\n",
            "\n",
            "In generation  10\n",
            "Number of estimated functional faults: 558\n",
            "Number of reward faults: 27\n",
            "Number of non-faults: 882\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run4_0.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run4_1.pickle\n",
            "In generation  1\n",
            "Number of estimated functional faults: 485\n",
            "Number of reward faults: 3\n",
            "Number of non-faults: 1008\n",
            "\n",
            "\n",
            "In generation  2\n",
            "Number of estimated functional faults: 577\n",
            "Number of reward faults: 5\n",
            "Number of non-faults: 914\n",
            "\n",
            "\n",
            "In generation  3\n",
            "Number of estimated functional faults: 643\n",
            "Number of reward faults: 1\n",
            "Number of non-faults: 856\n",
            "\n",
            "\n",
            "In generation  4\n",
            "Number of estimated functional faults: 695\n",
            "Number of reward faults: 6\n",
            "Number of non-faults: 804\n",
            "\n",
            "\n",
            "In generation  5\n",
            "Number of estimated functional faults: 672\n",
            "Number of reward faults: 6\n",
            "Number of non-faults: 827\n",
            "\n",
            "\n",
            "In generation  6\n",
            "Number of estimated functional faults: 694\n",
            "Number of reward faults: 12\n",
            "Number of non-faults: 821\n",
            "\n",
            "\n",
            "In generation  7\n",
            "Number of estimated functional faults: 656\n",
            "Number of reward faults: 8\n",
            "Number of non-faults: 848\n",
            "\n",
            "\n",
            "In generation  8\n",
            "Number of estimated functional faults: 598\n",
            "Number of reward faults: 18\n",
            "Number of non-faults: 885\n",
            "\n",
            "\n",
            "In generation  9\n",
            "Number of estimated functional faults: 623\n",
            "Number of reward faults: 32\n",
            "Number of non-faults: 843\n",
            "\n",
            "\n",
            "In generation  10\n",
            "Number of estimated functional faults: 635\n",
            "Number of reward faults: 40\n",
            "Number of non-faults: 810\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run4_1.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run4_2.pickle\n",
            "In generation  1\n",
            "Number of estimated functional faults: 515\n",
            "Number of reward faults: 2\n",
            "Number of non-faults: 977\n",
            "\n",
            "\n",
            "In generation  2\n",
            "Number of estimated functional faults: 559\n",
            "Number of reward faults: 5\n",
            "Number of non-faults: 914\n",
            "\n",
            "\n",
            "In generation  3\n",
            "Number of estimated functional faults: 619\n",
            "Number of reward faults: 2\n",
            "Number of non-faults: 853\n",
            "\n",
            "\n",
            "In generation  4\n",
            "Number of estimated functional faults: 678\n",
            "Number of reward faults: 3\n",
            "Number of non-faults: 804\n",
            "\n",
            "\n",
            "In generation  5\n",
            "Number of estimated functional faults: 674\n",
            "Number of reward faults: 6\n",
            "Number of non-faults: 781\n",
            "\n",
            "\n",
            "In generation  6\n",
            "Number of estimated functional faults: 641\n",
            "Number of reward faults: 10\n",
            "Number of non-faults: 808\n",
            "\n",
            "\n",
            "In generation  7\n",
            "Number of estimated functional faults: 649\n",
            "Number of reward faults: 13\n",
            "Number of non-faults: 806\n",
            "\n",
            "\n",
            "In generation  8\n",
            "Number of estimated functional faults: 669\n",
            "Number of reward faults: 11\n",
            "Number of non-faults: 779\n",
            "\n",
            "\n",
            "In generation  9\n",
            "Number of estimated functional faults: 647\n",
            "Number of reward faults: 11\n",
            "Number of non-faults: 804\n",
            "\n",
            "\n",
            "In generation  10\n",
            "Number of estimated functional faults: 624\n",
            "Number of reward faults: 22\n",
            "Number of non-faults: 806\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run4_2.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run4_3.pickle\n",
            "In generation  1\n",
            "Number of estimated functional faults: 526\n",
            "Number of reward faults: 2\n",
            "Number of non-faults: 944\n",
            "\n",
            "\n",
            "In generation  2\n",
            "Number of estimated functional faults: 620\n",
            "Number of reward faults: 2\n",
            "Number of non-faults: 872\n",
            "\n",
            "\n",
            "In generation  3\n",
            "Number of estimated functional faults: 645\n",
            "Number of reward faults: 2\n",
            "Number of non-faults: 839\n",
            "\n",
            "\n",
            "In generation  4\n",
            "Number of estimated functional faults: 650\n",
            "Number of reward faults: 7\n",
            "Number of non-faults: 823\n",
            "\n",
            "\n",
            "In generation  5\n",
            "Number of estimated functional faults: 672\n",
            "Number of reward faults: 5\n",
            "Number of non-faults: 820\n",
            "\n",
            "\n",
            "In generation  6\n",
            "Number of estimated functional faults: 647\n",
            "Number of reward faults: 8\n",
            "Number of non-faults: 826\n",
            "\n",
            "\n",
            "In generation  7\n",
            "Number of estimated functional faults: 609\n",
            "Number of reward faults: 15\n",
            "Number of non-faults: 851\n",
            "\n",
            "\n",
            "In generation  8\n",
            "Number of estimated functional faults: 644\n",
            "Number of reward faults: 12\n",
            "Number of non-faults: 844\n",
            "\n",
            "\n",
            "In generation  9\n",
            "Number of estimated functional faults: 599\n",
            "Number of reward faults: 17\n",
            "Number of non-faults: 876\n",
            "\n",
            "\n",
            "In generation  10\n",
            "Number of estimated functional faults: 522\n",
            "Number of reward faults: 23\n",
            "Number of non-faults: 953\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run4_3.pickle\n",
            "time: 1h 11min 50s (started: 2022-05-20 16:18:13 +00:00)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "#Input :  generated episodes with STARLA (Results of STARLA)\n",
        "items = os.listdir('/content/drive/MyDrive/GM/Results')\n",
        "# thresholds = [70, 0.04, 0.50, 0.50]\n",
        "thresholds = [70, 0.04, 0.50]\n",
        "for generations in items:\n",
        "  if generations=='res' or generations=='.ipynb_checkpoints':\n",
        "    continue\n",
        "  if generations[:17]==\"May17_generations\":\n",
        "    arch2=[]\n",
        "    stat=[]\n",
        "    ft=[]\n",
        "    print(\"\\n\\n-----------------------------------------------------\\n\\n\")\n",
        "    print(f'/content/drive/MyDrive/GM/Results/{generations}')\n",
        "    with open(f'/content/drive/MyDrive/GM/Results/{generations}', 'rb') as file2:\n",
        "        data = pickle.load(file2)\n",
        "    for i in range(len(data)):\n",
        "      if i == 0:\n",
        "        initial_pop = data[i]\n",
        "        continue\n",
        "      rewardfault = []\n",
        "      estimated_functional_faults=[] \n",
        "      nonfaulty=[]\n",
        "      epsilon = 0.05\n",
        "      for ind_ in data[i]:\n",
        "        last_state = ind_.get_candidate_values()[-2]\n",
        "        value_ = ind_.get_candidate_values()\n",
        "        objectives_ = ind_.get_objective_values()\n",
        "        if fitness_reward(value_)<thresholds[0]:\n",
        "          rewardfault.append(ind_)\n",
        "        if objectives_[2]<thresholds[2]:\n",
        "          estimated_functional_faults.append(ind_)\n",
        "        if fitness_reward(value_)>thresholds[0] and abs(last_state[0][0])<(2.4-epsilon):\n",
        "          nonfaulty.append(ind_)\n",
        "      print(\"In generation \", i )\n",
        "      print(\"Number of estimated functional faults:\",len(estimated_functional_faults))\n",
        "      print(\"Number of reward faults:\",len(rewardfault))\n",
        "      print(\"Number of non-faults:\",len(nonfaulty))\n",
        "      print(\"\\n\")\n",
        "      Build_Archive(data[i],len(thresholds),thresholds,arch2,initial_pop)\n",
        "    estimated_functional_faults_Archive=[] \n",
        "    for epis in arch2:\n",
        "      objectives_ = epis.get_objective_values()\n",
        "      if objectives_[2]<thresholds[2]:\n",
        "        estimated_functional_faults_Archive.append(epis)\n",
        "    print(f'/content/drive/MyDrive/GM/Results/{generations}')\n",
        "    re_exe_results=[]\n",
        "    for episode in estimated_functional_faults_Archive:\n",
        "      d1,d2,t = re_execute_final_ff_v1_woprint(model,env2,episode)\n",
        "      re_exe_results.append([d1,d2,t,episode])\n",
        "    with open(f'/content/drive/MyDrive/GM/Executions/re_executed{generations}', 'wb') as file:\n",
        "      pickle.dump(re_exe_results, file)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esUX4Z-n4SDr"
      },
      "source": [
        "#Re-execution for extracting similarities between states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqXiAWM64QiP",
        "outputId": "da973b3e-0371-4183-d2b2-4bae1be8faae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 32.7 ms (started: 2022-05-19 15:35:44 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def re_execute_final_ff_similarity_woprint(model,env,candidate):\n",
        "  differences=[]\n",
        "  episode_limit = 200 \n",
        "  env.reset()\n",
        "  obs =env.set_state(candidate.get_start_state()) \n",
        "  episode = candidate.get_candidate_values()\n",
        "  episode_reward = 0.0\n",
        "  done =False\n",
        "  diviate_counter = 0\n",
        "  divs=[]\n",
        "  States=[]\n",
        "  ff=False\n",
        "  for i in range(episode_limit):\n",
        "    if done:\n",
        "      if abs(obs[0])>=(2.4-epsilon):\n",
        "          ff = True\n",
        "      return differences ,divs, ff , States\n",
        "    if i >=(len(episode)-1):\n",
        "      action, _ = model.predict(obs, deterministic=True)\n",
        "      obs, reward, done, info = env.step(int(action)) \n",
        "      if done:\n",
        "        if abs(obs[0])>=(2.4-epsilon):\n",
        "          ff = True\n",
        "        return differences ,divs , ff, States\n",
        "      continue\n",
        "    action, _ = model.predict(obs, deterministic=True)\n",
        "    action1, _ = model.predict(episode[i][0], deterministic=True)\n",
        "    if action != int(episode[i][1]) and action1 != int(episode[i][1]):\n",
        "      prob=model.action_probability(episode[i][0])\n",
        "      differences.append([i , prob])\n",
        "    if action != int(episode[i][1]):\n",
        "      diviate_counter+=1\n",
        "      prob=model.action_probability(episode[i][0])\n",
        "      divs.append([i , prob])\n",
        "      States.append([obs,episode[i][0]])\n",
        "\n",
        "    obs, reward, done, info = env.step(int(action)) \n",
        "    episode_reward += reward\n",
        "  if abs(obs[0])>=(2.4-epsilon):\n",
        "    ff = True\n",
        "  assert done , \"not finished in 2oo steps \"\n",
        "  return differences ,divs , ff, States"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlW3dhQ39VmC",
        "outputId": "2c905766-6b70-4f11-cb9f-e5f676665c54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run0_0.pickle\n",
            "1 0\n",
            "2 1\n",
            "number of functional faults: 496\n",
            "number of reward faults: 3\n",
            "number of non-faults: 1001\n",
            "\n",
            "\n",
            "2 2\n",
            "number of functional faults: 567\n",
            "number of reward faults: 3\n",
            "number of non-faults: 931\n",
            "\n",
            "\n",
            "2 3\n",
            "number of functional faults: 595\n",
            "number of reward faults: 8\n",
            "number of non-faults: 897\n",
            "\n",
            "\n",
            "2 4\n",
            "number of functional faults: 637\n",
            "number of reward faults: 9\n",
            "number of non-faults: 854\n",
            "\n",
            "\n",
            "2 5\n",
            "number of functional faults: 622\n",
            "number of reward faults: 8\n",
            "number of non-faults: 870\n",
            "\n",
            "\n",
            "2 6\n",
            "number of functional faults: 638\n",
            "number of reward faults: 9\n",
            "number of non-faults: 854\n",
            "\n",
            "\n",
            "2 7\n",
            "number of functional faults: 616\n",
            "number of reward faults: 6\n",
            "number of non-faults: 877\n",
            "\n",
            "\n",
            "2 8\n",
            "number of functional faults: 598\n",
            "number of reward faults: 17\n",
            "number of non-faults: 885\n",
            "\n",
            "\n",
            "2 9\n",
            "number of functional faults: 606\n",
            "number of reward faults: 18\n",
            "number of non-faults: 877\n",
            "\n",
            "\n",
            "2 10\n",
            "number of functional faults: 572\n",
            "number of reward faults: 28\n",
            "number of non-faults: 901\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run0_0.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run1_0.pickle\n",
            "1 0\n",
            "2 1\n",
            "number of functional faults: 477\n",
            "number of reward faults: 5\n",
            "number of non-faults: 1019\n",
            "\n",
            "\n",
            "2 2\n",
            "number of functional faults: 600\n",
            "number of reward faults: 3\n",
            "number of non-faults: 898\n",
            "\n",
            "\n",
            "2 3\n",
            "number of functional faults: 644\n",
            "number of reward faults: 4\n",
            "number of non-faults: 853\n",
            "\n",
            "\n",
            "2 4\n",
            "number of functional faults: 707\n",
            "number of reward faults: 2\n",
            "number of non-faults: 789\n",
            "\n",
            "\n",
            "2 5\n",
            "number of functional faults: 648\n",
            "number of reward faults: 7\n",
            "number of non-faults: 845\n",
            "\n",
            "\n",
            "2 6\n",
            "number of functional faults: 687\n",
            "number of reward faults: 11\n",
            "number of non-faults: 802\n",
            "\n",
            "\n",
            "2 7\n",
            "number of functional faults: 642\n",
            "number of reward faults: 12\n",
            "number of non-faults: 846\n",
            "\n",
            "\n",
            "2 8\n",
            "number of functional faults: 573\n",
            "number of reward faults: 18\n",
            "number of non-faults: 909\n",
            "\n",
            "\n",
            "2 9\n",
            "number of functional faults: 575\n",
            "number of reward faults: 20\n",
            "number of non-faults: 904\n",
            "\n",
            "\n",
            "2 10\n",
            "number of functional faults: 544\n",
            "number of reward faults: 21\n",
            "number of non-faults: 935\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run1_0.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run1_1.pickle\n",
            "1 0\n",
            "2 1\n",
            "number of functional faults: 493\n",
            "number of reward faults: 3\n",
            "number of non-faults: 1004\n",
            "\n",
            "\n",
            "2 2\n",
            "number of functional faults: 597\n",
            "number of reward faults: 3\n",
            "number of non-faults: 901\n",
            "\n",
            "\n",
            "2 3\n",
            "number of functional faults: 643\n",
            "number of reward faults: 2\n",
            "number of non-faults: 856\n",
            "\n",
            "\n",
            "2 4\n",
            "number of functional faults: 676\n",
            "number of reward faults: 7\n",
            "number of non-faults: 817\n",
            "\n",
            "\n",
            "2 5\n",
            "number of functional faults: 670\n",
            "number of reward faults: 9\n",
            "number of non-faults: 822\n",
            "\n",
            "\n",
            "2 6\n",
            "number of functional faults: 697\n",
            "number of reward faults: 10\n",
            "number of non-faults: 793\n",
            "\n",
            "\n",
            "2 7\n",
            "number of functional faults: 641\n",
            "number of reward faults: 13\n",
            "number of non-faults: 847\n",
            "\n",
            "\n",
            "2 8\n",
            "number of functional faults: 665\n",
            "number of reward faults: 11\n",
            "number of non-faults: 824\n",
            "\n",
            "\n",
            "2 9\n",
            "number of functional faults: 641\n",
            "number of reward faults: 31\n",
            "number of non-faults: 828\n",
            "\n",
            "\n",
            "2 10\n",
            "number of functional faults: 642\n",
            "number of reward faults: 41\n",
            "number of non-faults: 818\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run1_1.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run1_2.pickle\n",
            "1 0\n",
            "2 1\n",
            "number of functional faults: 477\n",
            "number of reward faults: 4\n",
            "number of non-faults: 1019\n",
            "\n",
            "\n",
            "2 2\n",
            "number of functional faults: 622\n",
            "number of reward faults: 6\n",
            "number of non-faults: 873\n",
            "\n",
            "\n",
            "2 3\n",
            "number of functional faults: 659\n",
            "number of reward faults: 2\n",
            "number of non-faults: 839\n",
            "\n",
            "\n",
            "2 4\n",
            "number of functional faults: 657\n",
            "number of reward faults: 9\n",
            "number of non-faults: 833\n",
            "\n",
            "\n",
            "2 5\n",
            "number of functional faults: 672\n",
            "number of reward faults: 10\n",
            "number of non-faults: 819\n",
            "\n",
            "\n",
            "2 6\n",
            "number of functional faults: 675\n",
            "number of reward faults: 8\n",
            "number of non-faults: 816\n",
            "\n",
            "\n",
            "2 7\n",
            "number of functional faults: 630\n",
            "number of reward faults: 7\n",
            "number of non-faults: 864\n",
            "\n",
            "\n",
            "2 8\n",
            "number of functional faults: 590\n",
            "number of reward faults: 14\n",
            "number of non-faults: 896\n",
            "\n",
            "\n",
            "2 9\n",
            "number of functional faults: 552\n",
            "number of reward faults: 19\n",
            "number of non-faults: 930\n",
            "\n",
            "\n",
            "2 10\n",
            "number of functional faults: 566\n",
            "number of reward faults: 27\n",
            "number of non-faults: 907\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run1_2.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run1_3.pickle\n",
            "1 0\n",
            "2 1\n",
            "number of functional faults: 555\n",
            "number of reward faults: 1\n",
            "number of non-faults: 944\n",
            "\n",
            "\n",
            "2 2\n",
            "number of functional faults: 655\n",
            "number of reward faults: 0\n",
            "number of non-faults: 846\n",
            "\n",
            "\n",
            "2 3\n",
            "number of functional faults: 662\n",
            "number of reward faults: 3\n",
            "number of non-faults: 834\n",
            "\n",
            "\n",
            "2 4\n",
            "number of functional faults: 689\n",
            "number of reward faults: 4\n",
            "number of non-faults: 808\n",
            "\n",
            "\n",
            "2 5\n",
            "number of functional faults: 702\n",
            "number of reward faults: 6\n",
            "number of non-faults: 793\n",
            "\n",
            "\n",
            "2 6\n",
            "number of functional faults: 708\n",
            "number of reward faults: 11\n",
            "number of non-faults: 781\n",
            "\n",
            "\n",
            "2 7\n",
            "number of functional faults: 687\n",
            "number of reward faults: 12\n",
            "number of non-faults: 801\n",
            "\n",
            "\n",
            "2 8\n",
            "number of functional faults: 667\n",
            "number of reward faults: 11\n",
            "number of non-faults: 822\n",
            "\n",
            "\n",
            "2 9\n",
            "number of functional faults: 635\n",
            "number of reward faults: 19\n",
            "number of non-faults: 847\n",
            "\n",
            "\n",
            "2 10\n",
            "number of functional faults: 624\n",
            "number of reward faults: 22\n",
            "number of non-faults: 854\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run1_3.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run2_0.pickle\n",
            "1 0\n",
            "2 1\n",
            "number of functional faults: 500\n",
            "number of reward faults: 1\n",
            "number of non-faults: 999\n",
            "\n",
            "\n",
            "2 2\n",
            "number of functional faults: 628\n",
            "number of reward faults: 5\n",
            "number of non-faults: 866\n",
            "\n",
            "\n",
            "2 3\n",
            "number of functional faults: 683\n",
            "number of reward faults: 4\n",
            "number of non-faults: 813\n",
            "\n",
            "\n",
            "2 4\n",
            "number of functional faults: 703\n",
            "number of reward faults: 4\n",
            "number of non-faults: 793\n",
            "\n",
            "\n",
            "2 5\n",
            "number of functional faults: 726\n",
            "number of reward faults: 13\n",
            "number of non-faults: 761\n",
            "\n",
            "\n",
            "2 6\n",
            "number of functional faults: 686\n",
            "number of reward faults: 11\n",
            "number of non-faults: 803\n",
            "\n",
            "\n",
            "2 7\n",
            "number of functional faults: 670\n",
            "number of reward faults: 15\n",
            "number of non-faults: 815\n",
            "\n",
            "\n",
            "2 8\n",
            "number of functional faults: 674\n",
            "number of reward faults: 18\n",
            "number of non-faults: 809\n",
            "\n",
            "\n",
            "2 9\n",
            "number of functional faults: 636\n",
            "number of reward faults: 23\n",
            "number of non-faults: 840\n",
            "\n",
            "\n",
            "2 10\n",
            "number of functional faults: 562\n",
            "number of reward faults: 37\n",
            "number of non-faults: 900\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run2_0.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run2_1.pickle\n",
            "1 0\n",
            "2 1\n",
            "number of functional faults: 508\n",
            "number of reward faults: 3\n",
            "number of non-faults: 989\n",
            "\n",
            "\n",
            "2 2\n",
            "number of functional faults: 571\n",
            "number of reward faults: 6\n",
            "number of non-faults: 924\n",
            "\n",
            "\n",
            "2 3\n",
            "number of functional faults: 654\n",
            "number of reward faults: 9\n",
            "number of non-faults: 838\n",
            "\n",
            "\n",
            "2 4\n",
            "number of functional faults: 643\n",
            "number of reward faults: 10\n",
            "number of non-faults: 848\n",
            "\n",
            "\n",
            "2 5\n",
            "number of functional faults: 691\n",
            "number of reward faults: 14\n",
            "number of non-faults: 795\n",
            "\n",
            "\n",
            "2 6\n",
            "number of functional faults: 651\n",
            "number of reward faults: 12\n",
            "number of non-faults: 836\n",
            "\n",
            "\n",
            "2 7\n",
            "number of functional faults: 666\n",
            "number of reward faults: 14\n",
            "number of non-faults: 821\n",
            "\n",
            "\n",
            "2 8\n",
            "number of functional faults: 648\n",
            "number of reward faults: 18\n",
            "number of non-faults: 835\n",
            "\n",
            "\n",
            "2 9\n",
            "number of functional faults: 642\n",
            "number of reward faults: 26\n",
            "number of non-faults: 832\n",
            "\n",
            "\n",
            "2 10\n",
            "number of functional faults: 631\n",
            "number of reward faults: 36\n",
            "number of non-faults: 832\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run2_1.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run2_2.pickle\n",
            "1 0\n",
            "2 1\n",
            "number of functional faults: 458\n",
            "number of reward faults: 6\n",
            "number of non-faults: 1036\n",
            "\n",
            "\n",
            "2 2\n",
            "number of functional faults: 559\n",
            "number of reward faults: 6\n",
            "number of non-faults: 936\n",
            "\n",
            "\n",
            "2 3\n",
            "number of functional faults: 597\n",
            "number of reward faults: 4\n",
            "number of non-faults: 899\n",
            "\n",
            "\n",
            "2 4\n",
            "number of functional faults: 624\n",
            "number of reward faults: 10\n",
            "number of non-faults: 867\n",
            "\n",
            "\n",
            "2 5\n",
            "number of functional faults: 681\n",
            "number of reward faults: 14\n",
            "number of non-faults: 806\n",
            "\n",
            "\n",
            "2 6\n",
            "number of functional faults: 661\n",
            "number of reward faults: 9\n",
            "number of non-faults: 830\n",
            "\n",
            "\n",
            "2 7\n",
            "number of functional faults: 694\n",
            "number of reward faults: 16\n",
            "number of non-faults: 790\n",
            "\n",
            "\n",
            "2 8\n",
            "number of functional faults: 701\n",
            "number of reward faults: 15\n",
            "number of non-faults: 785\n",
            "\n",
            "\n",
            "2 9\n",
            "number of functional faults: 700\n",
            "number of reward faults: 25\n",
            "number of non-faults: 775\n",
            "\n",
            "\n",
            "2 10\n",
            "number of functional faults: 646\n",
            "number of reward faults: 37\n",
            "number of non-faults: 818\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run2_2.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run2_3.pickle\n",
            "1 0\n",
            "2 1\n",
            "number of functional faults: 501\n",
            "number of reward faults: 2\n",
            "number of non-faults: 997\n",
            "\n",
            "\n",
            "2 2\n",
            "number of functional faults: 615\n",
            "number of reward faults: 0\n",
            "number of non-faults: 885\n",
            "\n",
            "\n",
            "2 3\n",
            "number of functional faults: 676\n",
            "number of reward faults: 5\n",
            "number of non-faults: 819\n",
            "\n",
            "\n",
            "2 4\n",
            "number of functional faults: 717\n",
            "number of reward faults: 3\n",
            "number of non-faults: 780\n",
            "\n",
            "\n",
            "2 5\n",
            "number of functional faults: 694\n",
            "number of reward faults: 7\n",
            "number of non-faults: 800\n",
            "\n",
            "\n",
            "2 6\n",
            "number of functional faults: 652\n",
            "number of reward faults: 9\n",
            "number of non-faults: 839\n",
            "\n",
            "\n",
            "2 7\n",
            "number of functional faults: 673\n",
            "number of reward faults: 4\n",
            "number of non-faults: 824\n",
            "\n",
            "\n",
            "2 8\n",
            "number of functional faults: 650\n",
            "number of reward faults: 13\n",
            "number of non-faults: 838\n",
            "\n",
            "\n",
            "2 9\n",
            "number of functional faults: 628\n",
            "number of reward faults: 15\n",
            "number of non-faults: 858\n",
            "\n",
            "\n",
            "2 10\n",
            "number of functional faults: 628\n",
            "number of reward faults: 22\n",
            "number of non-faults: 850\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run2_3.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run2_4.pickle\n",
            "1 0\n",
            "2 1\n",
            "number of functional faults: 481\n",
            "number of reward faults: 0\n",
            "number of non-faults: 1020\n",
            "\n",
            "\n",
            "2 2\n",
            "number of functional faults: 546\n",
            "number of reward faults: 3\n",
            "number of non-faults: 951\n",
            "\n",
            "\n",
            "2 3\n",
            "number of functional faults: 602\n",
            "number of reward faults: 7\n",
            "number of non-faults: 892\n",
            "\n",
            "\n",
            "2 4\n",
            "number of functional faults: 665\n",
            "number of reward faults: 4\n",
            "number of non-faults: 831\n",
            "\n",
            "\n",
            "2 5\n",
            "number of functional faults: 650\n",
            "number of reward faults: 14\n",
            "number of non-faults: 836\n",
            "\n",
            "\n",
            "2 6\n",
            "number of functional faults: 670\n",
            "number of reward faults: 3\n",
            "number of non-faults: 828\n",
            "\n",
            "\n",
            "2 7\n",
            "number of functional faults: 659\n",
            "number of reward faults: 16\n",
            "number of non-faults: 825\n",
            "\n",
            "\n",
            "2 8\n",
            "number of functional faults: 634\n",
            "number of reward faults: 14\n",
            "number of non-faults: 852\n",
            "\n",
            "\n",
            "2 9\n",
            "number of functional faults: 623\n",
            "number of reward faults: 22\n",
            "number of non-faults: 855\n",
            "\n",
            "\n",
            "2 10\n",
            "number of functional faults: 623\n",
            "number of reward faults: 33\n",
            "number of non-faults: 845\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run2_4.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run3_0.pickle\n",
            "1 0\n",
            "2 1\n",
            "number of functional faults: 509\n",
            "number of reward faults: 2\n",
            "number of non-faults: 989\n",
            "\n",
            "\n",
            "2 2\n",
            "number of functional faults: 608\n",
            "number of reward faults: 5\n",
            "number of non-faults: 887\n",
            "\n",
            "\n",
            "2 3\n",
            "number of functional faults: 624\n",
            "number of reward faults: 6\n",
            "number of non-faults: 870\n",
            "\n",
            "\n",
            "2 4\n",
            "number of functional faults: 692\n",
            "number of reward faults: 10\n",
            "number of non-faults: 798\n",
            "\n",
            "\n",
            "2 5\n",
            "number of functional faults: 678\n",
            "number of reward faults: 6\n",
            "number of non-faults: 816\n",
            "\n",
            "\n",
            "2 6\n",
            "number of functional faults: 674\n",
            "number of reward faults: 9\n",
            "number of non-faults: 817\n",
            "\n",
            "\n",
            "2 7\n",
            "number of functional faults: 689\n",
            "number of reward faults: 14\n",
            "number of non-faults: 798\n",
            "\n",
            "\n",
            "2 8\n",
            "number of functional faults: 643\n",
            "number of reward faults: 19\n",
            "number of non-faults: 839\n",
            "\n",
            "\n",
            "2 9\n",
            "number of functional faults: 631\n",
            "number of reward faults: 27\n",
            "number of non-faults: 840\n",
            "\n",
            "\n",
            "2 10\n",
            "number of functional faults: 625\n",
            "number of reward faults: 40\n",
            "number of non-faults: 834\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run3_0.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run3_1.pickle\n",
            "1 0\n",
            "2 1\n",
            "number of functional faults: 497\n",
            "number of reward faults: 0\n",
            "number of non-faults: 1003\n",
            "\n",
            "\n",
            "2 2\n",
            "number of functional faults: 523\n",
            "number of reward faults: 2\n",
            "number of non-faults: 975\n",
            "\n",
            "\n",
            "2 3\n",
            "number of functional faults: 651\n",
            "number of reward faults: 4\n",
            "number of non-faults: 845\n",
            "\n",
            "\n",
            "2 4\n",
            "number of functional faults: 663\n",
            "number of reward faults: 6\n",
            "number of non-faults: 831\n",
            "\n",
            "\n",
            "2 5\n",
            "number of functional faults: 656\n",
            "number of reward faults: 7\n",
            "number of non-faults: 837\n",
            "\n",
            "\n",
            "2 6\n",
            "number of functional faults: 635\n",
            "number of reward faults: 7\n",
            "number of non-faults: 858\n",
            "\n",
            "\n",
            "2 7\n",
            "number of functional faults: 665\n",
            "number of reward faults: 8\n",
            "number of non-faults: 828\n",
            "\n",
            "\n",
            "2 8\n",
            "number of functional faults: 612\n",
            "number of reward faults: 9\n",
            "number of non-faults: 880\n",
            "\n",
            "\n",
            "2 9\n",
            "number of functional faults: 582\n",
            "number of reward faults: 17\n",
            "number of non-faults: 901\n",
            "\n",
            "\n",
            "2 10\n",
            "number of functional faults: 526\n",
            "number of reward faults: 23\n",
            "number of non-faults: 952\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run3_1.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run3_2.pickle\n",
            "1 0\n",
            "2 1\n",
            "number of functional faults: 489\n",
            "number of reward faults: 1\n",
            "number of non-faults: 1011\n",
            "\n",
            "\n",
            "2 2\n",
            "number of functional faults: 607\n",
            "number of reward faults: 4\n",
            "number of non-faults: 889\n",
            "\n",
            "\n",
            "2 3\n",
            "number of functional faults: 675\n",
            "number of reward faults: 6\n",
            "number of non-faults: 819\n",
            "\n",
            "\n",
            "2 4\n",
            "number of functional faults: 654\n",
            "number of reward faults: 6\n",
            "number of non-faults: 840\n",
            "\n",
            "\n",
            "2 5\n",
            "number of functional faults: 671\n",
            "number of reward faults: 7\n",
            "number of non-faults: 823\n",
            "\n",
            "\n",
            "2 6\n",
            "number of functional faults: 678\n",
            "number of reward faults: 9\n",
            "number of non-faults: 814\n",
            "\n",
            "\n",
            "2 7\n",
            "number of functional faults: 639\n",
            "number of reward faults: 7\n",
            "number of non-faults: 855\n",
            "\n",
            "\n",
            "2 8\n",
            "number of functional faults: 610\n",
            "number of reward faults: 14\n",
            "number of non-faults: 876\n",
            "\n",
            "\n",
            "2 9\n",
            "number of functional faults: 597\n",
            "number of reward faults: 23\n",
            "number of non-faults: 881\n",
            "\n",
            "\n",
            "2 10\n",
            "number of functional faults: 585\n",
            "number of reward faults: 28\n",
            "number of non-faults: 887\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run3_2.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run3_3.pickle\n",
            "1 0\n",
            "2 1\n",
            "number of functional faults: 548\n",
            "number of reward faults: 0\n",
            "number of non-faults: 952\n",
            "\n",
            "\n",
            "2 2\n",
            "number of functional faults: 620\n",
            "number of reward faults: 2\n",
            "number of non-faults: 878\n",
            "\n",
            "\n",
            "2 3\n",
            "number of functional faults: 631\n",
            "number of reward faults: 4\n",
            "number of non-faults: 865\n",
            "\n",
            "\n",
            "2 4\n",
            "number of functional faults: 694\n",
            "number of reward faults: 11\n",
            "number of non-faults: 796\n",
            "\n",
            "\n",
            "2 5\n",
            "number of functional faults: 672\n",
            "number of reward faults: 4\n",
            "number of non-faults: 824\n",
            "\n",
            "\n",
            "2 6\n",
            "number of functional faults: 690\n",
            "number of reward faults: 6\n",
            "number of non-faults: 805\n",
            "\n",
            "\n",
            "2 7\n",
            "number of functional faults: 661\n",
            "number of reward faults: 9\n",
            "number of non-faults: 831\n",
            "\n",
            "\n",
            "2 8\n",
            "number of functional faults: 624\n",
            "number of reward faults: 13\n",
            "number of non-faults: 862\n",
            "\n",
            "\n",
            "2 9\n",
            "number of functional faults: 663\n",
            "number of reward faults: 18\n",
            "number of non-faults: 816\n",
            "\n",
            "\n",
            "2 10\n",
            "number of functional faults: 597\n",
            "number of reward faults: 24\n",
            "number of non-faults: 878\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run3_3.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run3_4.pickle\n",
            "1 0\n",
            "2 1\n",
            "number of functional faults: 560\n",
            "number of reward faults: 3\n",
            "number of non-faults: 938\n",
            "\n",
            "\n",
            "2 2\n",
            "number of functional faults: 611\n",
            "number of reward faults: 4\n",
            "number of non-faults: 885\n",
            "\n",
            "\n",
            "2 3\n",
            "number of functional faults: 665\n",
            "number of reward faults: 5\n",
            "number of non-faults: 830\n",
            "\n",
            "\n",
            "2 4\n",
            "number of functional faults: 680\n",
            "number of reward faults: 6\n",
            "number of non-faults: 815\n",
            "\n",
            "\n",
            "2 5\n",
            "number of functional faults: 713\n",
            "number of reward faults: 8\n",
            "number of non-faults: 779\n",
            "\n",
            "\n",
            "2 6\n",
            "number of functional faults: 684\n",
            "number of reward faults: 17\n",
            "number of non-faults: 800\n",
            "\n",
            "\n",
            "2 7\n",
            "number of functional faults: 665\n",
            "number of reward faults: 14\n",
            "number of non-faults: 822\n",
            "\n",
            "\n",
            "2 8\n",
            "number of functional faults: 626\n",
            "number of reward faults: 20\n",
            "number of non-faults: 854\n",
            "\n",
            "\n",
            "2 9\n",
            "number of functional faults: 572\n",
            "number of reward faults: 28\n",
            "number of non-faults: 900\n",
            "\n",
            "\n",
            "2 10\n",
            "number of functional faults: 554\n",
            "number of reward faults: 35\n",
            "number of non-faults: 912\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run3_4.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run3_5.pickle\n",
            "1 0\n",
            "2 1\n",
            "number of functional faults: 546\n",
            "number of reward faults: 2\n",
            "number of non-faults: 952\n",
            "\n",
            "\n",
            "2 2\n",
            "number of functional faults: 644\n",
            "number of reward faults: 3\n",
            "number of non-faults: 853\n",
            "\n",
            "\n",
            "2 3\n",
            "number of functional faults: 667\n",
            "number of reward faults: 8\n",
            "number of non-faults: 825\n",
            "\n",
            "\n",
            "2 4\n",
            "number of functional faults: 712\n",
            "number of reward faults: 8\n",
            "number of non-faults: 781\n",
            "\n",
            "\n",
            "2 5\n",
            "number of functional faults: 672\n",
            "number of reward faults: 9\n",
            "number of non-faults: 819\n",
            "\n",
            "\n",
            "2 6\n",
            "number of functional faults: 683\n",
            "number of reward faults: 14\n",
            "number of non-faults: 803\n",
            "\n",
            "\n",
            "2 7\n",
            "number of functional faults: 729\n",
            "number of reward faults: 11\n",
            "number of non-faults: 761\n",
            "\n",
            "\n",
            "2 8\n",
            "number of functional faults: 674\n",
            "number of reward faults: 24\n",
            "number of non-faults: 803\n",
            "\n",
            "\n",
            "2 9\n",
            "number of functional faults: 668\n",
            "number of reward faults: 31\n",
            "number of non-faults: 802\n",
            "\n",
            "\n",
            "2 10\n",
            "number of functional faults: 646\n",
            "number of reward faults: 41\n",
            "number of non-faults: 814\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run3_5.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run4_0.pickle\n",
            "1 0\n",
            "2 1\n",
            "number of functional faults: 504\n",
            "number of reward faults: 2\n",
            "number of non-faults: 994\n",
            "\n",
            "\n",
            "2 2\n",
            "number of functional faults: 625\n",
            "number of reward faults: 7\n",
            "number of non-faults: 868\n",
            "\n",
            "\n",
            "2 3\n",
            "number of functional faults: 684\n",
            "number of reward faults: 8\n",
            "number of non-faults: 809\n",
            "\n",
            "\n",
            "2 4\n",
            "number of functional faults: 683\n",
            "number of reward faults: 7\n",
            "number of non-faults: 810\n",
            "\n",
            "\n",
            "2 5\n",
            "number of functional faults: 706\n",
            "number of reward faults: 11\n",
            "number of non-faults: 784\n",
            "\n",
            "\n",
            "2 6\n",
            "number of functional faults: 768\n",
            "number of reward faults: 8\n",
            "number of non-faults: 725\n",
            "\n",
            "\n",
            "2 7\n",
            "number of functional faults: 713\n",
            "number of reward faults: 11\n",
            "number of non-faults: 776\n",
            "\n",
            "\n",
            "2 8\n",
            "number of functional faults: 662\n",
            "number of reward faults: 13\n",
            "number of non-faults: 825\n",
            "\n",
            "\n",
            "2 9\n",
            "number of functional faults: 643\n",
            "number of reward faults: 26\n",
            "number of non-faults: 832\n",
            "\n",
            "\n",
            "2 10\n",
            "number of functional faults: 592\n",
            "number of reward faults: 27\n",
            "number of non-faults: 882\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run4_0.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run4_1.pickle\n",
            "1 0\n",
            "2 1\n",
            "number of functional faults: 489\n",
            "number of reward faults: 3\n",
            "number of non-faults: 1008\n",
            "\n",
            "\n",
            "2 2\n",
            "number of functional faults: 581\n",
            "number of reward faults: 5\n",
            "number of non-faults: 914\n",
            "\n",
            "\n",
            "2 3\n",
            "number of functional faults: 644\n",
            "number of reward faults: 1\n",
            "number of non-faults: 856\n",
            "\n",
            "\n",
            "2 4\n",
            "number of functional faults: 690\n",
            "number of reward faults: 6\n",
            "number of non-faults: 804\n",
            "\n",
            "\n",
            "2 5\n",
            "number of functional faults: 668\n",
            "number of reward faults: 6\n",
            "number of non-faults: 827\n",
            "\n",
            "\n",
            "2 6\n",
            "number of functional faults: 668\n",
            "number of reward faults: 12\n",
            "number of non-faults: 821\n",
            "\n",
            "\n",
            "2 7\n",
            "number of functional faults: 644\n",
            "number of reward faults: 8\n",
            "number of non-faults: 848\n",
            "\n",
            "\n",
            "2 8\n",
            "number of functional faults: 597\n",
            "number of reward faults: 18\n",
            "number of non-faults: 885\n",
            "\n",
            "\n",
            "2 9\n",
            "number of functional faults: 625\n",
            "number of reward faults: 32\n",
            "number of non-faults: 843\n",
            "\n",
            "\n",
            "2 10\n",
            "number of functional faults: 649\n",
            "number of reward faults: 40\n",
            "number of non-faults: 810\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run4_1.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run4_2.pickle\n",
            "1 0\n",
            "2 1\n",
            "number of functional faults: 521\n",
            "number of reward faults: 2\n",
            "number of non-faults: 977\n",
            "\n",
            "\n",
            "2 2\n",
            "number of functional faults: 582\n",
            "number of reward faults: 5\n",
            "number of non-faults: 914\n",
            "\n",
            "\n",
            "2 3\n",
            "number of functional faults: 646\n",
            "number of reward faults: 2\n",
            "number of non-faults: 853\n",
            "\n",
            "\n",
            "2 4\n",
            "number of functional faults: 693\n",
            "number of reward faults: 3\n",
            "number of non-faults: 804\n",
            "\n",
            "\n",
            "2 5\n",
            "number of functional faults: 714\n",
            "number of reward faults: 6\n",
            "number of non-faults: 781\n",
            "\n",
            "\n",
            "2 6\n",
            "number of functional faults: 683\n",
            "number of reward faults: 10\n",
            "number of non-faults: 808\n",
            "\n",
            "\n",
            "2 7\n",
            "number of functional faults: 681\n",
            "number of reward faults: 13\n",
            "number of non-faults: 806\n",
            "\n",
            "\n",
            "2 8\n",
            "number of functional faults: 710\n",
            "number of reward faults: 11\n",
            "number of non-faults: 779\n",
            "\n",
            "\n",
            "2 9\n",
            "number of functional faults: 685\n",
            "number of reward faults: 11\n",
            "number of non-faults: 804\n",
            "\n",
            "\n",
            "2 10\n",
            "number of functional faults: 671\n",
            "number of reward faults: 22\n",
            "number of non-faults: 806\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run4_2.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run4_3.pickle\n",
            "1 0\n",
            "2 1\n",
            "number of functional faults: 554\n",
            "number of reward faults: 2\n",
            "number of non-faults: 944\n",
            "\n",
            "\n",
            "2 2\n",
            "number of functional faults: 627\n",
            "number of reward faults: 2\n",
            "number of non-faults: 872\n",
            "\n",
            "\n",
            "2 3\n",
            "number of functional faults: 660\n",
            "number of reward faults: 2\n",
            "number of non-faults: 839\n",
            "\n",
            "\n",
            "2 4\n",
            "number of functional faults: 670\n",
            "number of reward faults: 7\n",
            "number of non-faults: 823\n",
            "\n",
            "\n",
            "2 5\n",
            "number of functional faults: 675\n",
            "number of reward faults: 5\n",
            "number of non-faults: 820\n",
            "\n",
            "\n",
            "2 6\n",
            "number of functional faults: 667\n",
            "number of reward faults: 8\n",
            "number of non-faults: 826\n",
            "\n",
            "\n",
            "2 7\n",
            "number of functional faults: 634\n",
            "number of reward faults: 15\n",
            "number of non-faults: 851\n",
            "\n",
            "\n",
            "2 8\n",
            "number of functional faults: 645\n",
            "number of reward faults: 12\n",
            "number of non-faults: 844\n",
            "\n",
            "\n",
            "2 9\n",
            "number of functional faults: 606\n",
            "number of reward faults: 17\n",
            "number of non-faults: 876\n",
            "\n",
            "\n",
            "2 10\n",
            "number of functional faults: 525\n",
            "number of reward faults: 23\n",
            "number of non-faults: 953\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/Results/May17_generations_r110_rt70_population1500lastfull_run4_3.pickle\n",
            "time: 4h 55min 30s (started: 2022-05-19 15:43:12 +00:00)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "items = os.listdir('/content/drive/MyDrive/GM/Results')\n",
        "# thresholds = [70, 0.04, 0.50, 0.50]\n",
        "thresholds = [70, 0.04, 0.50]\n",
        "\n",
        "for generations in items:\n",
        "  if generations=='res' or generations=='.ipynb_checkpoints':\n",
        "    continue\n",
        "  if generations[:17]==\"May17_generations\":\n",
        "    arch2=[]\n",
        "    stat=[]\n",
        "    ft=[]\n",
        "    print(\"\\n\\n-----------------------------------------------------\\n\\n\")\n",
        "    print(f'/content/drive/MyDrive/GM/Results/{generations}')\n",
        "    with open(f'/content/drive/MyDrive/GM/Results/{generations}', 'rb') as file2:\n",
        "        data = pickle.load(file2)\n",
        "    for i in range(len(data)):\n",
        "      if i == 0:\n",
        "        initial_pop = data[i]\n",
        "        print(\"1\",i)\n",
        "        continue\n",
        "      print('2',i)\n",
        "      rewardfault = []\n",
        "      functionalfault =[] \n",
        "      nonfaulty=[]\n",
        "      epsilon = 0.05\n",
        "      for ind_ in data[i]:\n",
        "        # obj_ = ind_.get_objective_values()\n",
        "        last_state = ind_.get_candidate_values()[-2]\n",
        "        value_ = ind_.get_candidate_values()\n",
        "        if fitness_reward(value_)<70:\n",
        "          rewardfault.append(ind_)\n",
        "        if abs(last_state[0][0])>(2.4-epsilon):\n",
        "          functionalfault.append(ind_)\n",
        "        if fitness_reward(value_)>70 and abs(last_state[0][0])<(2.4-epsilon):\n",
        "          nonfaulty.append(ind_)\n",
        "      ft.append(functionalfault)\n",
        "      print(\"number of functional faults:\",len(functionalfault))\n",
        "      print(\"number of reward faults:\",len(rewardfault))\n",
        "      print(\"number of non-faults:\",len(nonfaulty))\n",
        "      print(\"\\n\")\n",
        "      stat.append([len(functionalfault),(len(functionalfault)+len(nonfaulty)),len(rewardfault)])\n",
        "      Build_Archive(data[i],len(thresholds),thresholds,arch2,initial_pop)\n",
        "    estimated_functional_faults=[] \n",
        "    for epis in arch2:\n",
        "      objectives_ = epis.get_objective_values()\n",
        "      if objectives_[2]<thresholds[2]:\n",
        "        estimated_functional_faults.append(epis)\n",
        "    print(f'/content/drive/MyDrive/GM/Results/{generations}')\n",
        "    re_exe_results=[]\n",
        "    for episode in estimated_functional_faults:\n",
        "      d1,d2,t,states = re_execute_final_ff_similarity_woprint(model,env2,episode)\n",
        "      re_exe_results.append([d1,d2,t,states,episode])\n",
        "    with open(f'/content/drive/MyDrive/GM/Execution-Similarity/re_executed-sim-{generations}', 'wb') as file:\n",
        "      pickle.dump(re_exe_results, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wb6DM_SaQZ93"
      },
      "source": [
        "#Distribution of fitness values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "po62qkbbZnUv"
      },
      "outputs": [],
      "source": [
        "def extract_objective_distribution(population):\n",
        "  fit1_list =[] \n",
        "  fit2_list =[]\n",
        "  fit3_list =[]\n",
        "  fit4_list =[]\n",
        "  for i in range(len(population)):\n",
        "    ind_obj = population[i].get_objective_values()\n",
        "    fit1 = ind_obj[0]\n",
        "    fit2 = ind_obj[1]\n",
        "    fit3 = ind_obj[2]\n",
        "    fit4 = ind_obj[3]\n",
        "    fit1_list.append(fit1)\n",
        "    fit2_list.append(fit2)\n",
        "    fit3_list.append(fit3)\n",
        "    fit4_list.append(fit4)\n",
        "  return   fit1_list, fit2_list, fit3_list, fit4_list "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbMDDvz_-3lz",
        "outputId": "50787dd4-8bc0-4b81-d616-71b651ed4081"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/GM/execution4_gen/Copy of March018_generations_r110_rt70_population1500lastfull_run1_3.pickle\n",
            "time: 1min 2s (started: 2022-05-13 16:11:39 +00:00)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "items = os.listdir('/content/drive/MyDrive/GM/Results')\n",
        "thresholds = [70, 0.04, 0.30, 0.30]\n",
        "generations = items[1]  # select one sample from the executions we selected 5th execution\n",
        "arch2=[]\n",
        "stat=[]\n",
        "ft=[]\n",
        "print(\"\\n\\n-----------------------------------------------------\\n\\n\")\n",
        "print(f'/content/drive/MyDrive/GM/Results/{generations}')\n",
        "with open(f'/content/drive/MyDrive/GM/Result/{generations}', 'rb') as file2:\n",
        "    data = pickle.load(file2)\n",
        "for i in range(len(data)):\n",
        "  if i == 0:\n",
        "    initial_pop = data[i]\n",
        "    continue\n",
        "  Build_Archive(data[i],4,thresholds,arch2,initial_pop)\n",
        "#inja khareje for \n",
        "f1,f2,f3,f4 = extract_objective_distribution(initial_pop)\n",
        "v1,v2,v3,v4 = extract_objective_distribution(arch2)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8pGsPiSqXWqX",
        "outputId": "7f5858ad-deda-42a0-f5fb-008c19f4d4c0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3208: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  return asarray(a).size\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/cbook/__init__.py:1376: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  X = np.atleast_1d(X.T if isinstance(X, np.ndarray) else np.asarray(X))\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 1.41 s (started: 2022-05-13 16:13:19 +00:00)\n"
          ]
        }
      ],
      "source": [
        "plt.hist([f1,v1])\n",
        "plt.title('Reward')\n",
        "plt.show()\n",
        "# plt.stop()\n",
        "plt.hist([f2,v2])\n",
        "plt.title('Certainity level')\n",
        "plt.show()\n",
        "# plt.stop()\n",
        "plt.hist([f3,v3])\n",
        "plt.title('Inverse of probability of functional fault')\n",
        "\n",
        "plt.show()\n",
        "# plt.stop()\n",
        "plt.hist([f4,v4])\n",
        "plt.title('Inverse of probability of reward fault')\n",
        "\n",
        "plt.show()\n",
        "# plt.stop()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#Revision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "C:/Users/Student/Desktop/replication-package/Gen/May17_generations_r110_rt70_population1500lastfull_run0_0.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "C:/Users/Student/Desktop/replication-package/Gen/May17_generations_r110_rt70_population1500lastfull_run1_0.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "C:/Users/Student/Desktop/replication-package/Gen/May17_generations_r110_rt70_population1500lastfull_run1_1.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "C:/Users/Student/Desktop/replication-package/Gen/May17_generations_r110_rt70_population1500lastfull_run1_2.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "C:/Users/Student/Desktop/replication-package/Gen/May17_generations_r110_rt70_population1500lastfull_run1_3.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "C:/Users/Student/Desktop/replication-package/Gen/May17_generations_r110_rt70_population1500lastfull_run2_0.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "C:/Users/Student/Desktop/replication-package/Gen/May17_generations_r110_rt70_population1500lastfull_run2_1.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "C:/Users/Student/Desktop/replication-package/Gen/May17_generations_r110_rt70_population1500lastfull_run2_2.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "C:/Users/Student/Desktop/replication-package/Gen/May17_generations_r110_rt70_population1500lastfull_run2_3.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "C:/Users/Student/Desktop/replication-package/Gen/May17_generations_r110_rt70_population1500lastfull_run2_4.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "C:/Users/Student/Desktop/replication-package/Gen/May17_generations_r110_rt70_population1500lastfull_run3_0.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "C:/Users/Student/Desktop/replication-package/Gen/May17_generations_r110_rt70_population1500lastfull_run3_1.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "C:/Users/Student/Desktop/replication-package/Gen/May17_generations_r110_rt70_population1500lastfull_run3_2.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "C:/Users/Student/Desktop/replication-package/Gen/May17_generations_r110_rt70_population1500lastfull_run3_3.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "C:/Users/Student/Desktop/replication-package/Gen/May17_generations_r110_rt70_population1500lastfull_run3_4.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "C:/Users/Student/Desktop/replication-package/Gen/May17_generations_r110_rt70_population1500lastfull_run3_5.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "C:/Users/Student/Desktop/replication-package/Gen/May17_generations_r110_rt70_population1500lastfull_run4_0.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "C:/Users/Student/Desktop/replication-package/Gen/May17_generations_r110_rt70_population1500lastfull_run4_1.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "C:/Users/Student/Desktop/replication-package/Gen/May17_generations_r110_rt70_population1500lastfull_run4_2.pickle\n",
            "\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "\n",
            "C:/Users/Student/Desktop/replication-package/Gen/May17_generations_r110_rt70_population1500lastfull_run4_3.pickle\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "items = os.listdir('C:/Users/Student/Desktop/replication-package/Gen')\n",
        "# thresholds = [70, 0.04, 0.50]\n",
        "unseen_abstract_states=[]\n",
        "unseen_c_states =[]\n",
        "T_unseen_abstract_states=[]\n",
        "T_unseen_c_states =[]\n",
        "for generations in items[:]:\n",
        "  unseen_abstract_states_buff=[]\n",
        "  unseen_c_states_buff =[]\n",
        "  T_unseen_abstract_states_buff=[]\n",
        "  T_unseen_c_states_buff =[]\n",
        "  arch2=[]\n",
        "  stat=[]\n",
        "  ft=[]\n",
        "  print(\"\\n\\n-----------------------------------------------------\\n\\n\")\n",
        "  print(f'C:/Users/Student/Desktop/replication-package/Gen/{generations}')\n",
        "  with open(f'C:/Users/Student/Desktop/replication-package/Gen/{generations}', 'rb') as file2:\n",
        "    data = pickle.load(file2)\n",
        "  for i in range(len(data)):\n",
        "    if i==0:\n",
        "      initial_pop = data[i]\n",
        "      continue\n",
        "    rewardfault = []\n",
        "    functionalfault =[] \n",
        "    nonfaulty=[]\n",
        "    epsilon = 0.05\n",
        "    for ind_ in data[i]:\n",
        "      last_state = ind_.get_candidate_values()[-2]\n",
        "      value_ = ind_.get_candidate_values()\n",
        "      for state, action in value_:\n",
        "        ab = abstract_state(model,state,d)\n",
        "        if ab == 'end':\n",
        "          continue\n",
        "        if ab not in unique1:\n",
        "          T_unseen_abstract_states_buff.append(ab)\n",
        "          T_unseen_c_states_buff.append(state)  \n",
        "  T_unseen_abstract_states.append(T_unseen_abstract_states_buff)\n",
        "  T_unseen_c_states.append(T_unseen_c_states_buff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "209.55"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "unseen_abs_avg =sum(unseen_abs_count)/len(unseen_abs_count)\n",
        "unseen_abs_avg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average number of unseen abstract states is: 209.55\n"
          ]
        }
      ],
      "source": [
        "print(\"Average number of unseen abstract states is:\",unseen_abs_avg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of abstract states: 1035\n"
          ]
        }
      ],
      "source": [
        "print(\"Total number of abstract states:\",len(unique1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def change_threshold_in_similarity_data(new_threshold,results):\n",
        "  return_set=[]\n",
        "  for re_exe in results:\n",
        "    episode = re_exe[4]\n",
        "    ff_prob = episode.get_objective_values()[2]\n",
        "    if ff_prob<=new_threshold:\n",
        "      return_set.append(re_exe)\n",
        "  return return_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C:/Users/Student/Desktop/replication-package/v3/Execution-Similarity/re_executed-sim-May17_generations_r110_rt70_population1500lastfull_run0_0.pickle\n",
            "C:/Users/Student/Desktop/replication-package/v3/Execution-Similarity/re_executed-sim-May17_generations_r110_rt70_population1500lastfull_run1_0.pickle\n",
            "C:/Users/Student/Desktop/replication-package/v3/Execution-Similarity/re_executed-sim-May17_generations_r110_rt70_population1500lastfull_run1_1.pickle\n",
            "C:/Users/Student/Desktop/replication-package/v3/Execution-Similarity/re_executed-sim-May17_generations_r110_rt70_population1500lastfull_run1_2.pickle\n",
            "C:/Users/Student/Desktop/replication-package/v3/Execution-Similarity/re_executed-sim-May17_generations_r110_rt70_population1500lastfull_run1_3.pickle\n",
            "C:/Users/Student/Desktop/replication-package/v3/Execution-Similarity/re_executed-sim-May17_generations_r110_rt70_population1500lastfull_run2_0.pickle\n",
            "C:/Users/Student/Desktop/replication-package/v3/Execution-Similarity/re_executed-sim-May17_generations_r110_rt70_population1500lastfull_run2_1.pickle\n",
            "C:/Users/Student/Desktop/replication-package/v3/Execution-Similarity/re_executed-sim-May17_generations_r110_rt70_population1500lastfull_run2_2.pickle\n",
            "C:/Users/Student/Desktop/replication-package/v3/Execution-Similarity/re_executed-sim-May17_generations_r110_rt70_population1500lastfull_run2_3.pickle\n",
            "C:/Users/Student/Desktop/replication-package/v3/Execution-Similarity/re_executed-sim-May17_generations_r110_rt70_population1500lastfull_run2_4.pickle\n",
            "C:/Users/Student/Desktop/replication-package/v3/Execution-Similarity/re_executed-sim-May17_generations_r110_rt70_population1500lastfull_run3_0.pickle\n",
            "C:/Users/Student/Desktop/replication-package/v3/Execution-Similarity/re_executed-sim-May17_generations_r110_rt70_population1500lastfull_run3_1.pickle\n",
            "C:/Users/Student/Desktop/replication-package/v3/Execution-Similarity/re_executed-sim-May17_generations_r110_rt70_population1500lastfull_run3_2.pickle\n",
            "C:/Users/Student/Desktop/replication-package/v3/Execution-Similarity/re_executed-sim-May17_generations_r110_rt70_population1500lastfull_run3_3.pickle\n",
            "C:/Users/Student/Desktop/replication-package/v3/Execution-Similarity/re_executed-sim-May17_generations_r110_rt70_population1500lastfull_run3_4.pickle\n",
            "C:/Users/Student/Desktop/replication-package/v3/Execution-Similarity/re_executed-sim-May17_generations_r110_rt70_population1500lastfull_run3_5.pickle\n",
            "C:/Users/Student/Desktop/replication-package/v3/Execution-Similarity/re_executed-sim-May17_generations_r110_rt70_population1500lastfull_run4_0.pickle\n",
            "C:/Users/Student/Desktop/replication-package/v3/Execution-Similarity/re_executed-sim-May17_generations_r110_rt70_population1500lastfull_run4_1.pickle\n",
            "C:/Users/Student/Desktop/replication-package/v3/Execution-Similarity/re_executed-sim-May17_generations_r110_rt70_population1500lastfull_run4_2.pickle\n",
            "C:/Users/Student/Desktop/replication-package/v3/Execution-Similarity/re_executed-sim-May17_generations_r110_rt70_population1500lastfull_run4_3.pickle\n"
          ]
        }
      ],
      "source": [
        "from scipy.spatial.distance import cosine,euclidean\n",
        "replaced_cosine=[]\n",
        "episode_length =[]\n",
        "replaced_counter=[]\n",
        "pff = 0.5\n",
        "\n",
        "items = os.listdir('C:/Users/Student/Desktop/replication-package/v3/Execution-Similarity')\n",
        "for re_exe in items[:]:\n",
        "  CosineDistance=[]\n",
        "  final_consistent_ff = []\n",
        "  # print(\"\\n\\n-----------------------------------------------------\\n\\n\")\n",
        "  print(f'C:/Users/Student/Desktop/replication-package/v3/Execution-Similarity/{re_exe}')\n",
        "  with open(f'C:/Users/Student/Desktop/replication-package/v3/Execution-Similarity/{re_exe}', 'rb') as file2:\n",
        "      data = pickle.load(file2)\n",
        "  new_data = change_threshold_in_similarity_data(pff,data)\n",
        "  for result in new_data:\n",
        "    inconsistent, div , ff, states, episode = result\n",
        "    if ff:\n",
        "      if not inconsistent:\n",
        "        final_consistent_ff.append(result)\n",
        "        replaced_counter.append(len(states))\n",
        "        episode_length.append(len(episode.get_candidate_values()))\n",
        "        CosineDistance=[]\n",
        "        for st in states:\n",
        "          if cosine(st[0],st[1])>1.2:\n",
        "            break\n",
        "          CosineDistance.append(cosine(st[0],st[1]))\n",
        "        replaced_cosine.append(CosineDistance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "42.494810412655895"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "avg_replaced = sum(replaced_counter)/len(replaced_counter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average number of replaced states: 42.494810412655895\n"
          ]
        }
      ],
      "source": [
        "print(\"Average number of replaced states:\", avg_replaced)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "129.4668745291705"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "average_len_epis = sum(episode_length)/len(episode_length)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average length of episodes 129.4668745291705\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"Average length of episodes\",average_len_epis)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "v4_sMe_mKvA8"
      ],
      "name": "gt-final re_execute2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.7.8 ('venv')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "704142a53cc302aff65c9d37244a965c0815bdc7e36e6b2c7e9e17e0904d256a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
